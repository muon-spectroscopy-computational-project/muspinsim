{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MuSpinSim's documentation MuSpinSim is a program designed to carry out spin dynamics calculations for muon science experiments. MuSpinSim can: simulate zero, transverse and longitudinal field experiments simulate experiments resolved in time, field, or temperature include the effects of hyperfine, dipolar, quadrupolar and Zeeman couplings simulate quantum systems exchanging energy with the environment with the Lindblad master equation fit experimental data with simulations using all of the above run in parallel on multiple cores for the most expensive tasks How to install Follow the installation instructions here . Topics Learn about the theory of spin dynamics behind MuSpinSim ; go into more detail into the Hamiltonian used in simulations; follow the tutorial ; check out the list of input keywords ; or learn by doing through our many examples !","title":"Welcome to MuSpinSim's documentation"},{"location":"#welcome-to-muspinsims-documentation","text":"MuSpinSim is a program designed to carry out spin dynamics calculations for muon science experiments. MuSpinSim can: simulate zero, transverse and longitudinal field experiments simulate experiments resolved in time, field, or temperature include the effects of hyperfine, dipolar, quadrupolar and Zeeman couplings simulate quantum systems exchanging energy with the environment with the Lindblad master equation fit experimental data with simulations using all of the above run in parallel on multiple cores for the most expensive tasks","title":"Welcome to MuSpinSim's documentation"},{"location":"#how-to-install","text":"Follow the installation instructions here .","title":"How to install"},{"location":"#topics","text":"Learn about the theory of spin dynamics behind MuSpinSim ; go into more detail into the Hamiltonian used in simulations; follow the tutorial ; check out the list of input keywords ; or learn by doing through our many examples !","title":"Topics"},{"location":"examples/","text":"Examples Here we go over a few examples of usage of MuSpinSim which cover some common use cases. The examples can be found in the examples folder. Example 1 - Zeeman coupling Input file: examples/zeeman/zeeman.in This is a very simple example of a single muon with a static magnetic field - a Zeeman interaction. The field is set to be zeeman 1 0 0 20.0/muon_gyr Being aligned with the z axis, it will produce a full precession of the entire muon polarisation, and given the field is defined as a function of the muon gyromagnetic ratio, it will result in a Larmor frequency of \\(\\gamma_\\mu B = 20 \\,\\mathrm{MHz}\\) , meaning it will do two full precessions in the 0.1 \u00b5s range covered by the time axis. Example 2 - Hyperfine coupling Input file: examples/hfine/hfine.in This example is for the simplified case of a muon and an electron with isotropic hyperfine coupling and zero magnetic field. The hyperfine tensor has a Fermi contact term of 10 MHz: hyperfine 1 10 0 0 0 10 0 0 0 10 so we expect an oscillation of the muon's polarisation at that frequency. Example 3 - Hyperfine coupling (with powder averaging) Input file: examples/hfine_powder/hfine_powder.in A similar example as the first, but this time, an anisotropic hyperfine tensor including a dipolar part is used: hyperfine 1 5 2 3 2 5 2 3 2 5 In addition, a full averaging over 1,000 solid angles is carried out: orientation eulrange(10) Each of these orientations will contribute an oscillation like the one above with a slightly different frequency. The overall sum of all contributions ends up decaying due to the dephased individual oscillations cancelling out. Example 4 - Avoided Level Crossing Input file: examples/alc/alc.in A simple example of an Avoided Level Crossing experiment involving three spins: a muon, an electron, and a hydrogen atom. Both the muon and the hydrogen are coupled to the electron by the hyperfine interaction. The tensors are orientation dependent, and an average is carried out over different orientations (because this is an experiment with longitudinal polarisation, the zcw averaging should be sufficient, and is much cheaper than eulrange ). The result can be seen as one major \\(\\Delta_1\\) peak around 2.1 T and a much smaller \\(\\Delta_0\\) one at 2.3 T. Example 5 - Finite temperature Input files: examples/temperature/low_T.in , examples/temperature/high_T.in In this example we look at the effect of temperature on the starting density matrix of the system, and how it affects the final result. We work with a system very similar to that of example 2 , with the difference that we add an external static field of 1 T. This means that the difference in energy between the \"up\" and \"down\" states for the electron is given by: \\[ \\Delta E = 2\\pi\\hbar \\gamma_e \\cdot (1 \\,\\mathrm{T}) = 2\\pi\\hbar \\cdot (28024.95 \\,\\mathrm{MHz}) \\approx 1.159\\cdot 10^{-4} \\,\\mathrm{eV} \\] The scale of this energy is much higher than anything that can come out of the hyperfine coupling between electron and muon (only 10 MHz), so we're safely in the area of validity of the high field approximation. In terms of temperature scale, we expect the high temperature ( \\(T \\approx \\infty\\) ) regime will be valid for \\[ T \\gg \\frac{1.159\\cdot 10^{-4} \\,\\mathrm{eV}}{ k_B} \\approx 1.35 \\,\\mathrm{K}. \\] For this reason, we make a comparison between two versions of the same system, one with \\(T=\\infty\\) and one with \\(T = 1 \\,\\mathrm{K}\\) , low enough to be out of the high temperature regime. The expected behaviour is as follows: the external field sets a base Larmor frequency of 135.54 MHz for the muon. The hyperfine interaction adds or subtracts 5 MHz based on whether the electron is up or down; for very low T, the electron will start entirely in one state, aligned with the external magnetic field. In this case we expect the signal to be a single cosinusoid at 140.54 MHz; for very high T, the electron will be in a statistical ensemble of up and down state, and we expect the signal to be an average of two cosinusoids at 140.54 and 130.54 MHz respectively. We can see the trends very obviously in the figure below. The high temperature limit corresponds to the sum of two slightly dephased cosinusoids, while the low temperature example is closer to a single wave. You can try experimenting with changing the temperature and re-running the simulation to see how it affects the result. Example 6 - Dissipation Input file: example/dissipation/dissipation.in This example shows exactly the case that was solved analytically in the theory section about the Lindbladian . A system is set up with a single muon polarised in the x direction, a perpendicular field, and a dissipation constant. The system is defined as follows: field 2.0/muon_gyr dissipation 1 5.0 Thus, following the theory as described, we expect to observe a signal that has the equation \\[ A(t) = \\frac{1}{2} \\cos(4\\pi t)e^{-5t} \\] where the time is in microseconds. We can in fact see this exact result in the figure below: Example 7 - Fluorine Input files: examples/fluorine/fluorine_zf.in , examples/fluorine/fluorine_tf.in This example draws inspiration from an important paper in muon science, namely: J. H. Brewer, S. R. Kreitzman, D. R. Noakes, E. J. Ansaldo, D. R. Harshman, and R. Keitel Observation of muon-fluorine \"hydrogen bonding\" in ionic crystals Phys. Rev. B 33, 7813(R) \u2013 Published 1 June 1986 In this paper, it was observed that in some ionic fluorides, muons tend to form a \\(\\mathrm{F}-\\mu-\\mathrm{F}\\) complex that then becomes recognisable due to the specific signature of the dipolar coupling of the muon with the two fluorine nuclei. The input file uses the paper's estimated distances for NaF (sodium fluoride) for both Zero Field (ZF) and Transverse Field (TF) cases. Dipolar couplings are defined taking into account that the bond is in the \\(\\langle 110\\rangle\\) direction in the crystal: dipolar 1 2 0.82731493 0.82731493 0 dipolar 1 3 -0.82731493 -0.82731493 0 while the muon starts polarised along x , namely, the \\(\\langle 100\\rangle\\) direction. Let's first look at the TF case. Here the field is aligned to the \\(\\langle 111 \\rangle\\) direction and has an intensity of 220 Oe (corresponding to 0.022 T): field 1.27e-2 1.27e-2 1.27e-2 # Original paper uses field in Oe, direction <111> This result is meant to be compared with Fig. 1 of the paper: One can see the similarity at the beginning, though at longer time scales, the experimental data decays a lot more quickly. This is due to how in the real experiment, of course, there aren't just three spins - there is a whole lattice of them. The fluorine nuclei in particular interact with other neighbouring nuclei via dipolar coupling, and that ends up causing a phenomenon known as 'spin diffusion' in which the polarisation is irreversibly dispersed throughout the crystal, and thus the muon loses it almost entirely. Here is instead the ZF experiment. This is meant to be compared with Fig. 3 of the paper, the bottom left quadrant: Again, the same principle holds, as the similarity is stronger for \\(t \\lt 4 \\,\\mu\\mathrm{s}\\) and then is lost as the effect of spin diffusion becomes more pronounced. Example 8 - Fluorine with dissipation Input files: examples/fluorine_dissipation/fluorine_tf_dissip.in and examples/fluorine_dissipation/fluorine_zf_dissip.in We saw above how the simulation of the \\(\\mathrm{F}-\\mu-\\mathrm{F}\\) complex is accurate only at short time due to spin diffusion affecting the system. We can, however, try to approximate the effect of spin diffusion too. To this end we add dissipative terms to the two fluorine nuclei, as a way to represent the effect of exchange with the reserve of other fluorine spins in the crystal. The couplings here have been worked out to match the experimental result. dissipation 2 0.1 dissipation 3 0.1 The results in this way show a marked decay towards the end of the plot, for both transverse field: and zero field: and if you can compare with the original paper, you can notice how these are already much more similar to the look of the experimental results. Example 9 - Fitting Input file: examples/fitting/fitting.in Now, we look at how we can fit some data with MuSpinSim. Here we use again the same system seen in the dissipation example , but we use some fake simulated data (found in examples/fitting/experiment.dat ) calculated from the analytical solution to the problem with some added random noise. The data is formatted in two columns and normalised so that it begins around 0.5 intensity, and then is loaded in the input file: fitting_data load(\"experiment.dat\") Then we define a variable g with a starting value of 0.1 and comprised between 0 and \\(+\\infty\\) and use it to define the dissipation: fitting_variables g 0.1 0.0 inf dissipation 1 g Running this example will take a bit longer than the others, as the program needs to evaluate the function a lot of times to find the correct value. At the end, it should converge on a value close to g = 3.0 , and as we can see here, the fitted function matches the fake data quite well: Example 10 - Celio's Method Input file: examples/celio/celio.in Finally, we look at how we can use Celio's method to approximate a large system with MuSpinSim. Here we give an example of \\(\\text{V}_3\\text{Si}\\) as described in the paper Pietro Bonf\u00e0, Jonathan Frassineti, John M. Wilkinson, Giacomo Prando, Muhammad Maikudi Isah, Chennan Wang, Tiziana Spina, Boby Joseph, Vesna F. Mitrovi\u0107, Roberto De Renzi, Stephen J. Blundell, and Samuele Sanna Entanglement between Muon and \\(I > \\frac{1}{2}\\) Nuclear Spins as a Probe of Charge Environment Phys. Rev. Lett. 129 , 097205 \u2013 Published 26 August 2022 In brief, this system consists of Si atoms each with 0 spin, and Vanadium atoms each with a spin \\(\\frac{7}{2}\\) . Since the Si atoms have 0 spin, we only consider interactions between the muon and the Vanadium atoms. We now want to find 4 closest Vanadium atoms to the muon stopping site and consider their dipole interactions with the muon as well as their quadrupole interactions. To do this we use GIPAW to compute the EFG tensors required for the quadrupole interactions and use the muspinsim-gen tool to construct the beginnings of our input file using the command muspinsim-gen ./V3Si_SC.cell 6 --dipolar --quadrupolar ./gipaw.out --ignore_symbol Si --out V3Si.in . We then give it a name and define the time range we want to compute the asymmetry values for using name celio time range(0, 10, 50) Then we average over simulations with muons initially polarised in the x, y and z directions by adding polarization 1 0 0 0 1 0 0 0 1 average_axes polarization Finally we request that MuSpinSim uses Celio's method using celio 10 4 Where the first value is the trotter number \\(k = 10\\) , and the second value gets MuSpinSim to randomise the initial states and compute the average of 4 simulations for each initial polarisation direction. Running this example will take longer than the others due to the size of the problem (in this case we have a Hilbert space of dimension \\(2\\times8^4 = 8192\\) ), but without using Celio's method it would have taken many times longer and would require a lot more memory. The result looks like Figure 2(a) in the paper:","title":"Examples"},{"location":"examples/#examples","text":"Here we go over a few examples of usage of MuSpinSim which cover some common use cases. The examples can be found in the examples folder.","title":"Examples"},{"location":"examples/#example-1-zeeman-coupling","text":"Input file: examples/zeeman/zeeman.in This is a very simple example of a single muon with a static magnetic field - a Zeeman interaction. The field is set to be zeeman 1 0 0 20.0/muon_gyr Being aligned with the z axis, it will produce a full precession of the entire muon polarisation, and given the field is defined as a function of the muon gyromagnetic ratio, it will result in a Larmor frequency of \\(\\gamma_\\mu B = 20 \\,\\mathrm{MHz}\\) , meaning it will do two full precessions in the 0.1 \u00b5s range covered by the time axis.","title":"Example 1 - Zeeman coupling"},{"location":"examples/#example-2-hyperfine-coupling","text":"Input file: examples/hfine/hfine.in This example is for the simplified case of a muon and an electron with isotropic hyperfine coupling and zero magnetic field. The hyperfine tensor has a Fermi contact term of 10 MHz: hyperfine 1 10 0 0 0 10 0 0 0 10 so we expect an oscillation of the muon's polarisation at that frequency.","title":"Example 2 - Hyperfine coupling"},{"location":"examples/#example-3-hyperfine-coupling-with-powder-averaging","text":"Input file: examples/hfine_powder/hfine_powder.in A similar example as the first, but this time, an anisotropic hyperfine tensor including a dipolar part is used: hyperfine 1 5 2 3 2 5 2 3 2 5 In addition, a full averaging over 1,000 solid angles is carried out: orientation eulrange(10) Each of these orientations will contribute an oscillation like the one above with a slightly different frequency. The overall sum of all contributions ends up decaying due to the dephased individual oscillations cancelling out.","title":"Example 3 - Hyperfine coupling (with powder averaging)"},{"location":"examples/#example-4-avoided-level-crossing","text":"Input file: examples/alc/alc.in A simple example of an Avoided Level Crossing experiment involving three spins: a muon, an electron, and a hydrogen atom. Both the muon and the hydrogen are coupled to the electron by the hyperfine interaction. The tensors are orientation dependent, and an average is carried out over different orientations (because this is an experiment with longitudinal polarisation, the zcw averaging should be sufficient, and is much cheaper than eulrange ). The result can be seen as one major \\(\\Delta_1\\) peak around 2.1 T and a much smaller \\(\\Delta_0\\) one at 2.3 T.","title":"Example 4 - Avoided Level Crossing"},{"location":"examples/#example-5-finite-temperature","text":"Input files: examples/temperature/low_T.in , examples/temperature/high_T.in In this example we look at the effect of temperature on the starting density matrix of the system, and how it affects the final result. We work with a system very similar to that of example 2 , with the difference that we add an external static field of 1 T. This means that the difference in energy between the \"up\" and \"down\" states for the electron is given by: \\[ \\Delta E = 2\\pi\\hbar \\gamma_e \\cdot (1 \\,\\mathrm{T}) = 2\\pi\\hbar \\cdot (28024.95 \\,\\mathrm{MHz}) \\approx 1.159\\cdot 10^{-4} \\,\\mathrm{eV} \\] The scale of this energy is much higher than anything that can come out of the hyperfine coupling between electron and muon (only 10 MHz), so we're safely in the area of validity of the high field approximation. In terms of temperature scale, we expect the high temperature ( \\(T \\approx \\infty\\) ) regime will be valid for \\[ T \\gg \\frac{1.159\\cdot 10^{-4} \\,\\mathrm{eV}}{ k_B} \\approx 1.35 \\,\\mathrm{K}. \\] For this reason, we make a comparison between two versions of the same system, one with \\(T=\\infty\\) and one with \\(T = 1 \\,\\mathrm{K}\\) , low enough to be out of the high temperature regime. The expected behaviour is as follows: the external field sets a base Larmor frequency of 135.54 MHz for the muon. The hyperfine interaction adds or subtracts 5 MHz based on whether the electron is up or down; for very low T, the electron will start entirely in one state, aligned with the external magnetic field. In this case we expect the signal to be a single cosinusoid at 140.54 MHz; for very high T, the electron will be in a statistical ensemble of up and down state, and we expect the signal to be an average of two cosinusoids at 140.54 and 130.54 MHz respectively. We can see the trends very obviously in the figure below. The high temperature limit corresponds to the sum of two slightly dephased cosinusoids, while the low temperature example is closer to a single wave. You can try experimenting with changing the temperature and re-running the simulation to see how it affects the result.","title":"Example 5 - Finite temperature"},{"location":"examples/#example-6-dissipation","text":"Input file: example/dissipation/dissipation.in This example shows exactly the case that was solved analytically in the theory section about the Lindbladian . A system is set up with a single muon polarised in the x direction, a perpendicular field, and a dissipation constant. The system is defined as follows: field 2.0/muon_gyr dissipation 1 5.0 Thus, following the theory as described, we expect to observe a signal that has the equation \\[ A(t) = \\frac{1}{2} \\cos(4\\pi t)e^{-5t} \\] where the time is in microseconds. We can in fact see this exact result in the figure below:","title":"Example 6 - Dissipation"},{"location":"examples/#example-7-fluorine","text":"Input files: examples/fluorine/fluorine_zf.in , examples/fluorine/fluorine_tf.in This example draws inspiration from an important paper in muon science, namely: J. H. Brewer, S. R. Kreitzman, D. R. Noakes, E. J. Ansaldo, D. R. Harshman, and R. Keitel Observation of muon-fluorine \"hydrogen bonding\" in ionic crystals Phys. Rev. B 33, 7813(R) \u2013 Published 1 June 1986 In this paper, it was observed that in some ionic fluorides, muons tend to form a \\(\\mathrm{F}-\\mu-\\mathrm{F}\\) complex that then becomes recognisable due to the specific signature of the dipolar coupling of the muon with the two fluorine nuclei. The input file uses the paper's estimated distances for NaF (sodium fluoride) for both Zero Field (ZF) and Transverse Field (TF) cases. Dipolar couplings are defined taking into account that the bond is in the \\(\\langle 110\\rangle\\) direction in the crystal: dipolar 1 2 0.82731493 0.82731493 0 dipolar 1 3 -0.82731493 -0.82731493 0 while the muon starts polarised along x , namely, the \\(\\langle 100\\rangle\\) direction. Let's first look at the TF case. Here the field is aligned to the \\(\\langle 111 \\rangle\\) direction and has an intensity of 220 Oe (corresponding to 0.022 T): field 1.27e-2 1.27e-2 1.27e-2 # Original paper uses field in Oe, direction <111> This result is meant to be compared with Fig. 1 of the paper: One can see the similarity at the beginning, though at longer time scales, the experimental data decays a lot more quickly. This is due to how in the real experiment, of course, there aren't just three spins - there is a whole lattice of them. The fluorine nuclei in particular interact with other neighbouring nuclei via dipolar coupling, and that ends up causing a phenomenon known as 'spin diffusion' in which the polarisation is irreversibly dispersed throughout the crystal, and thus the muon loses it almost entirely. Here is instead the ZF experiment. This is meant to be compared with Fig. 3 of the paper, the bottom left quadrant: Again, the same principle holds, as the similarity is stronger for \\(t \\lt 4 \\,\\mu\\mathrm{s}\\) and then is lost as the effect of spin diffusion becomes more pronounced.","title":"Example 7 - Fluorine"},{"location":"examples/#example-8-fluorine-with-dissipation","text":"Input files: examples/fluorine_dissipation/fluorine_tf_dissip.in and examples/fluorine_dissipation/fluorine_zf_dissip.in We saw above how the simulation of the \\(\\mathrm{F}-\\mu-\\mathrm{F}\\) complex is accurate only at short time due to spin diffusion affecting the system. We can, however, try to approximate the effect of spin diffusion too. To this end we add dissipative terms to the two fluorine nuclei, as a way to represent the effect of exchange with the reserve of other fluorine spins in the crystal. The couplings here have been worked out to match the experimental result. dissipation 2 0.1 dissipation 3 0.1 The results in this way show a marked decay towards the end of the plot, for both transverse field: and zero field: and if you can compare with the original paper, you can notice how these are already much more similar to the look of the experimental results.","title":"Example 8 - Fluorine with dissipation"},{"location":"examples/#example-9-fitting","text":"Input file: examples/fitting/fitting.in Now, we look at how we can fit some data with MuSpinSim. Here we use again the same system seen in the dissipation example , but we use some fake simulated data (found in examples/fitting/experiment.dat ) calculated from the analytical solution to the problem with some added random noise. The data is formatted in two columns and normalised so that it begins around 0.5 intensity, and then is loaded in the input file: fitting_data load(\"experiment.dat\") Then we define a variable g with a starting value of 0.1 and comprised between 0 and \\(+\\infty\\) and use it to define the dissipation: fitting_variables g 0.1 0.0 inf dissipation 1 g Running this example will take a bit longer than the others, as the program needs to evaluate the function a lot of times to find the correct value. At the end, it should converge on a value close to g = 3.0 , and as we can see here, the fitted function matches the fake data quite well:","title":"Example 9 - Fitting"},{"location":"examples/#example-10-celios-method","text":"Input file: examples/celio/celio.in Finally, we look at how we can use Celio's method to approximate a large system with MuSpinSim. Here we give an example of \\(\\text{V}_3\\text{Si}\\) as described in the paper Pietro Bonf\u00e0, Jonathan Frassineti, John M. Wilkinson, Giacomo Prando, Muhammad Maikudi Isah, Chennan Wang, Tiziana Spina, Boby Joseph, Vesna F. Mitrovi\u0107, Roberto De Renzi, Stephen J. Blundell, and Samuele Sanna Entanglement between Muon and \\(I > \\frac{1}{2}\\) Nuclear Spins as a Probe of Charge Environment Phys. Rev. Lett. 129 , 097205 \u2013 Published 26 August 2022 In brief, this system consists of Si atoms each with 0 spin, and Vanadium atoms each with a spin \\(\\frac{7}{2}\\) . Since the Si atoms have 0 spin, we only consider interactions between the muon and the Vanadium atoms. We now want to find 4 closest Vanadium atoms to the muon stopping site and consider their dipole interactions with the muon as well as their quadrupole interactions. To do this we use GIPAW to compute the EFG tensors required for the quadrupole interactions and use the muspinsim-gen tool to construct the beginnings of our input file using the command muspinsim-gen ./V3Si_SC.cell 6 --dipolar --quadrupolar ./gipaw.out --ignore_symbol Si --out V3Si.in . We then give it a name and define the time range we want to compute the asymmetry values for using name celio time range(0, 10, 50) Then we average over simulations with muons initially polarised in the x, y and z directions by adding polarization 1 0 0 0 1 0 0 0 1 average_axes polarization Finally we request that MuSpinSim uses Celio's method using celio 10 4 Where the first value is the trotter number \\(k = 10\\) , and the second value gets MuSpinSim to randomise the initial states and compute the average of 4 simulations for each initial polarisation direction. Running this example will take longer than the others due to the size of the problem (in this case we have a Hilbert space of dimension \\(2\\times8^4 = 8192\\) ), but without using Celio's method it would have taken many times longer and would require a lot more memory. The result looks like Figure 2(a) in the paper:","title":"Example 10 - Celio's Method"},{"location":"hamiltonian/","text":"Hamiltonian In this section we will go a bit more in detail into the general Hamiltonian for a system in MuSpinSim, each term, and how they are defined and implemented. The generic Hamiltonian for any MuSpinSim simulation can be written as follows: \\[ \\mathcal{H} = \\mathcal{H}_Z + \\mathcal{H}_{hfine} + \\mathcal{H}_{dip} + \\mathcal{H}_Q \\] Where: \\(\\mathcal{H}_Z\\) is the Zeeman Hamiltonian \\(\\mathcal{H}_{hfine}\\) is the hyperfine Hamiltonian \\(\\mathcal{H}_{dip}\\) is the dipolar Hamiltonian \\(\\mathcal{H}_Q\\) is the quadrupolar Hamiltonian Let's now look at these more in detail. For developers: the system Hamiltonian is built by the SpinSystem class, found in muspinsim/spinsys.py . While here we detail the terms in energy units, in practice MuSpinSim internally uses Hamiltonians in frequency units, specifically, MHz. This tends to be a very natural choice of unit for these problems as it coincides with the units used for hyperfine tensors, and keeps the numbers small and manageable, minimising risks of over or underflow. Working in SI units, this would mean that to get them in Joule you'd have to multiply by a factor of \\(h\\cdot 10^6\\) . Zeeman Hamiltonian The Zeeman interaction is the interaction of any spin with an external magnetic field. In MuSpinSim this mainly means a strong global field applied to the entire experiment, though it is possible for the user to also set custom local magnetic fields for individual spins (representing for example the effect of nearby paramagnetic nuclei). The Hamiltonian written explicitly is: \\[ \\mathcal{H}_Z = 2\\pi\\hbar\\sum_i^N \\gamma_i (\\mathbf{B}+\\mathbf{B}_i)\\mathbf{S}_i \\] The sum is intended over all spins, with the gyromagnetic ratios \\(\\gamma_i\\) depending on the nuclei's own properties. The magnetic field here was split in two parts, a global and a local one which bears the index of the spin. Of course, both of these can be zero, and by default are if the user does not specify anything. \\(\\mathbf{S}_i\\) is the vector of spin operators. For developers: SpinSystem has an add_zeeman_term() method to deal with this term. Hyperfine Hamiltonian The hyperfine interaction is often the main interaction we care about in muon spin resonance simulations. It represents an interaction between an electronic spin and a nuclear one (muon or otherwise). While physically it is often distinguished in two terms - a Fermi contact term due to the electronic spin density at the site of the nucleus as well as a dipolar part at a distance - these are effectively both incorporated in a single \\(3 \\times 3\\) symmetric tensor with non-zero trace. The following interaction between spins is written like this: \\[ \\mathcal{H}_{hfine} = 2\\pi\\hbar \\sum_{i < j}^N \\mathbf{S}_i\\mathbf{A}_{ij}\\mathbf{S}_j \\] (assuming a hyperfine tensor \\(\\mathbf{A}_{ij}\\) in frequency units). MuSpinSim also makes sure that hyperfine terms can only be defined when one of the two spins is confirmed to be an electron. For developers: SpinSystem has an add_hyperfine_term() method to deal with this term. Dipolar Hamiltonian Dipole-dipole interactions are the result of one spin interacting with the magnetic field generated by a different one. Conceptually, they are not unlike hyperfine interactions. The differences between them are due to the fact that unlike with a muon or nucleus and an electron, both dipoles in this case are considered point-like. This leads to two consequences: there is no Fermi contact term, as the two spins don't overlap; therefore the tensor is traceless; both spins can be approximated as being localised at precise points, which gives a very well defined geometric formula for the interaction tensor between them that only depends on the vector connecting them. Given two spins \\(i\\) and \\(j\\) , and a vector connecting them \\(\\mathbf{r}_{ij}\\) , the dipolar tensor for them can be computed as: \\[ \\mathbf{D}_{ij} = -\\frac{\\mu_0\\hbar \\gamma_i \\gamma_j}{2|r_{ij}|^3}\\left(\\frac{3}{|r_{ij}|^2}\\mathbf{r}_{ij}\\otimes \\mathbf{r}_{ij} - \\mathbb{1} \\right) \\] This will return a tensor in frequency units, and thus the dipolar Hamiltonian can be defined like the hyperfine one: \\[ \\mathcal{H}_{dip} = 2\\pi\\hbar \\sum_{i < j}^N \\mathbf{S}_i\\mathbf{D}_{ij}\\mathbf{S}_j \\] Quadrupolar Hamiltonian Nuclei with spin greater than \u00bd can possess a quadrupole moment . This can be roughly understood in classical terms as the result of the nuclei's internal charge distribution (due to proton and neutron arrangement) not being perfectly symmetric, and the resulting inhomogeneities in the electrostatic field. Due to having spin 1/2, neither electrons, nor muons, nor protons possess a quadrupole moment. However, some other nuclei (most commonly, \\(^{14}N\\) ) do possess a quadrupole moment. In presence of an electric field gradient (EFG), this affects the energies of their spin levels through quadrupolar self-interaction. This can then indirectly affect the results of a muon experiment when the particle interacts with the quadrupolar nucleus either through dipolar or hyperfine coupling. For this reason, MuSpinSim includes the possibility of simulating quadrupolar interactions as well. The Hamiltonian term for quadrupolar interactions depends mainly on the EFG, which can be written as a \\(3 \\times 3\\) symmetric, traceless tensor: \\[ \\mathbf{Z} = \\begin{bmatrix} \\frac{\\partial E_x}{\\partial x} & \\frac{\\partial E_x}{\\partial y} & \\frac{\\partial E_x}{\\partial z} \\\\ \\frac{\\partial E_y}{\\partial x} & \\frac{\\partial E_y}{\\partial y} & \\frac{\\partial E_y}{\\partial z} \\\\ \\frac{\\partial E_z}{\\partial x} & \\frac{\\partial E_z}{\\partial y} & \\frac{\\partial E_z}{\\partial z} \\end{bmatrix} \\] The quadrupolar interaction Hamiltonian is then found as: \\[ \\mathcal{H}_Q = \\sum_{S_i > 1/2}^N \\frac{eQ_i}{2S_i(2S_i-1)}\\mathbf{S}_i\\mathbf{Z}_i\\mathbf{S}_i \\] where \\(e\\) is the elementary charge, \\(Q_i\\) the quadrupolar moment of the nucleus (these are tabulated, and MuSpinSim has data for most relevant isotopes of the periodic table) and \\(S_i\\) the spin of the nucleus.","title":"Hamiltonian"},{"location":"hamiltonian/#hamiltonian","text":"In this section we will go a bit more in detail into the general Hamiltonian for a system in MuSpinSim, each term, and how they are defined and implemented. The generic Hamiltonian for any MuSpinSim simulation can be written as follows: \\[ \\mathcal{H} = \\mathcal{H}_Z + \\mathcal{H}_{hfine} + \\mathcal{H}_{dip} + \\mathcal{H}_Q \\] Where: \\(\\mathcal{H}_Z\\) is the Zeeman Hamiltonian \\(\\mathcal{H}_{hfine}\\) is the hyperfine Hamiltonian \\(\\mathcal{H}_{dip}\\) is the dipolar Hamiltonian \\(\\mathcal{H}_Q\\) is the quadrupolar Hamiltonian Let's now look at these more in detail. For developers: the system Hamiltonian is built by the SpinSystem class, found in muspinsim/spinsys.py . While here we detail the terms in energy units, in practice MuSpinSim internally uses Hamiltonians in frequency units, specifically, MHz. This tends to be a very natural choice of unit for these problems as it coincides with the units used for hyperfine tensors, and keeps the numbers small and manageable, minimising risks of over or underflow. Working in SI units, this would mean that to get them in Joule you'd have to multiply by a factor of \\(h\\cdot 10^6\\) .","title":"Hamiltonian"},{"location":"hamiltonian/#zeeman-hamiltonian","text":"The Zeeman interaction is the interaction of any spin with an external magnetic field. In MuSpinSim this mainly means a strong global field applied to the entire experiment, though it is possible for the user to also set custom local magnetic fields for individual spins (representing for example the effect of nearby paramagnetic nuclei). The Hamiltonian written explicitly is: \\[ \\mathcal{H}_Z = 2\\pi\\hbar\\sum_i^N \\gamma_i (\\mathbf{B}+\\mathbf{B}_i)\\mathbf{S}_i \\] The sum is intended over all spins, with the gyromagnetic ratios \\(\\gamma_i\\) depending on the nuclei's own properties. The magnetic field here was split in two parts, a global and a local one which bears the index of the spin. Of course, both of these can be zero, and by default are if the user does not specify anything. \\(\\mathbf{S}_i\\) is the vector of spin operators. For developers: SpinSystem has an add_zeeman_term() method to deal with this term.","title":"Zeeman Hamiltonian"},{"location":"hamiltonian/#hyperfine-hamiltonian","text":"The hyperfine interaction is often the main interaction we care about in muon spin resonance simulations. It represents an interaction between an electronic spin and a nuclear one (muon or otherwise). While physically it is often distinguished in two terms - a Fermi contact term due to the electronic spin density at the site of the nucleus as well as a dipolar part at a distance - these are effectively both incorporated in a single \\(3 \\times 3\\) symmetric tensor with non-zero trace. The following interaction between spins is written like this: \\[ \\mathcal{H}_{hfine} = 2\\pi\\hbar \\sum_{i < j}^N \\mathbf{S}_i\\mathbf{A}_{ij}\\mathbf{S}_j \\] (assuming a hyperfine tensor \\(\\mathbf{A}_{ij}\\) in frequency units). MuSpinSim also makes sure that hyperfine terms can only be defined when one of the two spins is confirmed to be an electron. For developers: SpinSystem has an add_hyperfine_term() method to deal with this term.","title":"Hyperfine Hamiltonian"},{"location":"hamiltonian/#dipolar-hamiltonian","text":"Dipole-dipole interactions are the result of one spin interacting with the magnetic field generated by a different one. Conceptually, they are not unlike hyperfine interactions. The differences between them are due to the fact that unlike with a muon or nucleus and an electron, both dipoles in this case are considered point-like. This leads to two consequences: there is no Fermi contact term, as the two spins don't overlap; therefore the tensor is traceless; both spins can be approximated as being localised at precise points, which gives a very well defined geometric formula for the interaction tensor between them that only depends on the vector connecting them. Given two spins \\(i\\) and \\(j\\) , and a vector connecting them \\(\\mathbf{r}_{ij}\\) , the dipolar tensor for them can be computed as: \\[ \\mathbf{D}_{ij} = -\\frac{\\mu_0\\hbar \\gamma_i \\gamma_j}{2|r_{ij}|^3}\\left(\\frac{3}{|r_{ij}|^2}\\mathbf{r}_{ij}\\otimes \\mathbf{r}_{ij} - \\mathbb{1} \\right) \\] This will return a tensor in frequency units, and thus the dipolar Hamiltonian can be defined like the hyperfine one: \\[ \\mathcal{H}_{dip} = 2\\pi\\hbar \\sum_{i < j}^N \\mathbf{S}_i\\mathbf{D}_{ij}\\mathbf{S}_j \\]","title":"Dipolar Hamiltonian"},{"location":"hamiltonian/#quadrupolar-hamiltonian","text":"Nuclei with spin greater than \u00bd can possess a quadrupole moment . This can be roughly understood in classical terms as the result of the nuclei's internal charge distribution (due to proton and neutron arrangement) not being perfectly symmetric, and the resulting inhomogeneities in the electrostatic field. Due to having spin 1/2, neither electrons, nor muons, nor protons possess a quadrupole moment. However, some other nuclei (most commonly, \\(^{14}N\\) ) do possess a quadrupole moment. In presence of an electric field gradient (EFG), this affects the energies of their spin levels through quadrupolar self-interaction. This can then indirectly affect the results of a muon experiment when the particle interacts with the quadrupolar nucleus either through dipolar or hyperfine coupling. For this reason, MuSpinSim includes the possibility of simulating quadrupolar interactions as well. The Hamiltonian term for quadrupolar interactions depends mainly on the EFG, which can be written as a \\(3 \\times 3\\) symmetric, traceless tensor: \\[ \\mathbf{Z} = \\begin{bmatrix} \\frac{\\partial E_x}{\\partial x} & \\frac{\\partial E_x}{\\partial y} & \\frac{\\partial E_x}{\\partial z} \\\\ \\frac{\\partial E_y}{\\partial x} & \\frac{\\partial E_y}{\\partial y} & \\frac{\\partial E_y}{\\partial z} \\\\ \\frac{\\partial E_z}{\\partial x} & \\frac{\\partial E_z}{\\partial y} & \\frac{\\partial E_z}{\\partial z} \\end{bmatrix} \\] The quadrupolar interaction Hamiltonian is then found as: \\[ \\mathcal{H}_Q = \\sum_{S_i > 1/2}^N \\frac{eQ_i}{2S_i(2S_i-1)}\\mathbf{S}_i\\mathbf{Z}_i\\mathbf{S}_i \\] where \\(e\\) is the elementary charge, \\(Q_i\\) the quadrupolar moment of the nucleus (these are tabulated, and MuSpinSim has data for most relevant isotopes of the periodic table) and \\(S_i\\) the spin of the nucleus.","title":"Quadrupolar Hamiltonian"},{"location":"input/","text":"Input The input file format for MuSpinSim is a simple text file structured using keywords and values this way: keyword additional arguments value_1 value_2 Some keywords accept additional arguments, others don't. Values are on multiple rows; in some cases multiple values can be present on the same row. The most important thing is the indent: values have to be indented with respect to the keywords, if there are no spaces at the beginning of the line then they will be read as another keyword instead. In addition, in some keywords, special functions can be used in place of lengthy lists, as well as operations instead of simple numbers. An example file is the one you can find in /examples/basic/basic.in : name basic spins mu e hyperfine 1 10 0 0 0 10 0 0 0 10 time range(0, 0.1, 100) y_axis asymmetry This defines a system of a muon and an electron, coupled by an isotropic hyperfine tensor of 10 MHz, and will save a file containing the time evolution of the muon's polarization (asymmetry) from 0 to 0.1 microseconds, in 100 steps. Using expressions in keyword values One of the new features of MuSpinSim v1.0.0 is the option to use functions and variables in keyword values. These have a few uses: They can be used to access some meaningful mathematical or physical constants in place of numbers. For example, one can write 10.0*MHz as an applied magnetic field, and it will immediately be converted to the equivalent field in Tesla for an ALC resonance, as MHz = 1/(2*muon_gyr) , with the gyromagnetic ratio of the muon, muon_gyr = 135.5388 (in MHz/T). They can be used to generate large ranges of values automatically for some very common use cases. For example, the keyword time stores all the times at which the simulation should be performed. It's a common requirement to want to acquire hundreds or thousands of time points, regularly spaced. One could do this by writing hundreds or thousands of values in column, but it's a lot faster and easier to simply use something like range(0, 1, 100) to create 100 equally spaced time points going from 0 to 1 microseconds. They can be used to insert variables defined for fitting. For example one might define a hyperfine interaction tensor as a function of two parameters, then fit those parameters to find the optimal tensor that explains an experimental result. Expressions allow use of the operators + , - , * , / and ^ for exponentiation. Parentheses ( and ) can be used. Strings, if used, must be enclosed in double quotes \" . In the keyword list, below, which constants and functions are allowed for each keyword are specified. User-defined constants are currently not allowed: the only types of user-defined variables that can be used are the ones for fitting. By default, all keywords in which expressions can be used allow the following constants: pi : ratio of a circle and its diameter e : base of the natural logarithm deg : conversion factor between radians and degrees, equivalent to 180/pi inf : infinity and the following functions: sin(x) : sine cos(x) : cosine tan(x) : tangent arcsin(x) : inverse of the sine arccos(x) : inverse of the cosine arctan(x) : inverse of the tangent arctan2(y, x) : inverse of the tangent taking two arguments as (sine, cosine) to resolve the quadrant exp(x) : exponential with base e log(x) : natural logarithm sqrt(x) : square root These are all reserved names and can't be used as variable names. Using multiple lines for a keyword Some keywords accept an arbitrary amount of lines. This is different from keywords like hyperfine , that only take three lines so that the user can write a full matrix. Keywords that allow multiple rows are meant to allow the user to define ranges of values. When a range of values is defined, three things can happen: one range must always exist and will be specified as the x_axis of the system. This will be the range of values that appears on the first column of the output files. This is usually time , but it can also be, for example, field . some ranges are specified as average_axes and will be averaged over. This means that calculations will be carried for each value in these ranges and then they will all be summed over, and only the average will be printed out. A typical example of an axis to average over is orientation , to perform powder averages. any range that isn't specified in the previous two groups automatically means that the software will print out a different file for each value. When using ranges, remember that the number of calculations to perform grows very quickly with them. If one for example asked for an average over 100 different orientations, and to print out a file for each of 20 possible fields and 10 different temperatures, that would result in 100x20x10 = 20,000 individual simulations, and 20x10 = 200 files. The software doesn't have any specific safeguards against going overboard with them, but it's very easy if working on a simple desktop machine or laptop to just overwhelm its capabilities if one uses big ranges carelessly. MuSpinSim is reasonably well optimised and can be very fast for simple calculations, but complex systems and large ranges can make for very resource-intensive simulations. In the list of input keywords below, keywords that can be defined as a range are identified by the \"Allows multiple rows\" property. Input keywords Here is a list of accepted keywords and what they mean. spins Keyword: spins Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: spins mu e 2H A list of the spins to be used in the system. This has to include a muon ( mu ) and can contain one or more electrons ( e ). If only one electron is present, it will be the one all hyperfine couplings are with by default. Atomic species refer to the nuclei; so, for example, if you're trying to model the interaction of a muon with a paramagnetic electron on an iron atom, you want to use e , not Fe ; the actual spin is that of an electron, not a nucleus! In addition, in case of multiple strongly coupled electrons that can be treated as a single spin greater than 1/2, the isotope syntax can be used too, so for example 2e represents two electrons in a triplet state, acting as a single particle with the same gyromagnetic ratio as the electron, but spin 1. The default isotope is the most common one that has a non-zero spin. Other isotopes may be specified by writing the atomic mass as an integer before the symbol. By default, this is a muon and an electron. name Keyword: name Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: name mysystem A prefix to use for all files saved in this simulation. By default it's muspinsim . polarization Keyword: polarization Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, longitudinal , transverse Allows functions: default Example: polarization longitudinal The direction along which the muon should be polarized when starting, as well as the one in which it will be measured. It can be specified as a vector, and multiple values are allowed. The constants transverse and longitudinal are just useful shorthands for the X axis and the Z axis, respectively. Unless specified otherwise, the magnetic field is aligned along the Z axis. The default value is transverse . field Keyword: field Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, MHz , muon_gyr Allows functions: default, range Example: field 0 1*MHz 2*MHz 4*MHz A single or range of external magnetic fields, in Tesla, to simulate. These can be scalars or vectors; if scalars, the field will be assumed to be aligned with the Z axis. The function range expands into a number of values - by default, 50 of them, if only the start and end are specified. The default value is zero. This field type will be affected by any orientation changes such as when doing an angular average. intrinsic_field Keyword: intrinsic_field Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, MHz , muon_gyr Allows functions: default, range Example: intrinsic_field 0 1*MHz 2*MHz 4*MHz A single or range of intrinsic magnetic fields, in Tesla, to simulate. These can be scalars or vectors; if scalars, the field will be assumed to be aligned with the Z axis. The function range expands into a number of values - by default, 50 of them, if only the start and end are specified. The default value is zero. This field type will be unaffected by any orientation changes such as when doing an angular average. time Keyword: time Allows multiple rows: Yes Allows expressions: Yes Allows constants: default Allows functions: default, range Example: time range(0, 1, 100) A time or range of times, in microseconds, to simulate. Used by default as the x_axis . The function range expands into a number of values - by default, 50 of them, if only the start and end are specified. The default value is range(0, 10, 101) . x_axis Keyword: x_axis Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: x_axis field Which range to use as the X axis of the simulation's output files. Must be another keyword that accepts a range, and the given keyword must be specified as a range in this input file. When fitting, this is also assumed to be the X axis of the data to fit, and the range specified for this keyword is overridden by the fitting data. By default it's time . y_axis Keyword: y_axis Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: y_axis integral What to save as the Y axis of the simulation's output files: if the muon's polarization ( asymmetry ) or its integral over time, taking into account the exponential decay with the particle's half-life ( integral ). By default asymmetry , and can generally be ignored unless one is interested in Avoided Level Crossing experiments, which need integral . When set to integral , the time keyword is ignored and can not be the x_axis . average_axes Keyword: average_axes Allows multiple rows: Yes Allows expressions: No Allows constants: N/A Allows functions: N/A Example: average_axes orientation polarisation Any keywords that should have an average carried out over them (if they include a range of values). By default it's just orientation . Any axes with a range that aren't either x_axis or included here are automatically used for different files. orientation Keyword: orientation Allows multiple rows: Yes Allows expressions: Yes Allows constants: default Allows functions: default, zcw , eulrange Example: orientation zxz 45*deg 0 90*deg 1.0 90*deg 30*deg 60*deg 2.0 One or more orientations to use for the crystallites making up the system. Used to define powder averages. The rows can come in a number of ways: two numbers are interpreted as two polar angles \u03b8 and \u03d5, defining only the direction of the Z axis of the new system. This setting is recommended only for powder averages in which only the Z axis matters; typical example is an ALC calculation with both the magnetic field and the muon polarization aligned along Z. three numbers are interpreted as Euler angles defining a new frame. If there is no argument specified after orientation , the convention used is ZYZ. As seen in the example, it's possible to specify it to be ZXZ instead. four numbers are interpreted as Euler angles as above, plus one weight. The weights don't need to add up to one (they will be normalised). In this case, any average over these orientations will be weighted; otherwise, the weights will be ignored. Two helper functions are provided to generate automatically ranges of orientations for powder averages. zcw(N) creates N or more polar angle pairs using the Zaremba-Conroy-Wolfsberg algorithm to cover the sphere. It's cheap but only usable in cases in which polar angles are sufficient. eulrange(N) creates a regular grid of \\(N\\times N \\times N\\) Euler angles with appropriate weights. This covers the space of all possible orientations in 3D but can become a lot more expensive very quickly. temperature Keyword: temperature Allows multiple rows: Yes Allows expressions: Yes Allows constants: default Allows functions: default, range Example: temperature 273.0 Temperature in Kelvin of the system. This is used to determine the initial density matrix of the system, as every spin that is not the muon is put in a thermal state, and in case of dissipative systems, to determine the coupling to the thermal bath. By default, it is set to infinity. A warning: both density matrices and dissipative couplings for finite temperatures are only calculated approximatively, based on the individual Hamiltonians for each spin which only account for the applied magnetic field. In other words, these approximations are meant for high field experiments, and break down in the low field regime. Therefore, caution should be used when changing this variable or interpreting the resulting simulations. fitting_variables Keyword: fitting_variables Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, muon_gyr , MHz Allows functions: default Example: fitting_variables x y 1.0 0.0 5.0 Variables to fit to the experimental data. If present, the calculation is assumed to be a fitting, and the fitting_data keyword must be present too. The first letter in each row is the name of the variable; optionally, it can be followed in order by the starting value of the variable, the minimum bound, and the maximum bound (by default 0 , -inf and +inf ). It is important to notice that while expressions are accepted in the definition of value, minimum, and maximum, these can not contain the name of other variables. fitting_data Keyword: fitting_data Allows multiple rows: Yes Allows expressions: Yes Allows constants: none Allows functions: load Example: fitting_data load('results.dat') Block of data to fit. Must have two columns: the first one is the x_axis (for example, time), while the second is the expected result of the simulation. The function load can be used to load it from an ASCII tabulated file on disk, as long as it has only two columns. Note that the data must be normalized properly to match the conventions of MuSpinSim's output, so for example it must start from 0.5 at t = 0 (as that's the moment of the muon before it has had any time to evolve). fitting_method Keyword: fitting_method Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: fitting_method lbfgs Method to use to fit the data. Currently available are only nelder-mead (default) and lbfgs . fitting_tolerance Keyword: fitting_tolerance Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: fitting_tolerance 1e-4 Tolerance for the fitting. Used as the tol parameter in Scipy's scipy.optimize.minimize method; exact meaning depends on fitting method. Check the Scipy documentation for further details. experiment Keyword: experiment Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: experiment alc A convenience keyword that sets a number of other parameters to reproduce certain experimental setups. Possible values are alc (sets up an Avoided Level Crossing experiment: longitudinal polarization, field as x_axis , integral as y_axis ) and zero_field (sets field as 0 and polarization as transverse ). zeeman Keyword: zeeman Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: zeeman 1 2.0 2.0 0 Add a Zeeman coupling term specifying a local magnetic field, in Tesla, for a given spin. This coupling will be on top of the standard coupling with the external magnetic field from the laboratory, that always applies to all spins. The argument is the index of the coupled spin. Indices count from 1. hyperfine Keyword: hyperfine Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: hyperfine 1 100 10 10 10 100 10 10 10 100 Specify a hyperfine tensor, in MHz, for a given spin. A hyperfine tensor couples the spin with one electron in the system. If there is only one electron, then only one index can be indicated, and it's the index of the non-electron spin. If there is more than one electron in the system, more than one index must be indicated, and the second index must refer to an electron. The tensor must be written with three numbers per line. The argument (here 1 ) represents the index of the coupled spin. A second argument specifying the index of the electron is only obligatory if the system has more than one electron. Indices count from 1. Note that the block is always composed of three rows, but this is not interpreted as a range. dipolar Keyword: dipolar Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: dipolar 1 2 0 1 1 Specify a dipolar coupling between two spins. This is given by a vector connecting them, in Angstrom. The coupling tensor will be then calculated based on the known gyromagnetic ratios of those spins. The two arguments are the indices of the coupled spins. Indices count from 1. quadrupolar Keyword: quadrupolar Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: quadrupolar 3 100 10 10 10 100 10 10 10 -200 Specify a quadrupolar coupling for a spin by using an Electric Field Gradient tensor in atomic units (as returned by for example the DFT software CASTEP). The argument is the index of the spin. The coupling will then be calculated by using the known values of angular momentum and quadrupole moment for each spin. Spins with zero quadrupole moment (like hydrogen) will have zero coupling regardless of what is specified in this term. Indices count from 1. Note that the block is always composed of three rows, but this is not interpreted as a range. dissipation Keyword: dissipation Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: dissipation 1 0.5 Add a dissipation term for a given spin, which switches the system to using the Lindblad master equation instead of regular unitary quantim evolution. The dissipative term will cause random spin flips that decohere the system and drive it towards a thermal equilibrium state (determined by the temperature). The dissipation term is given in MHz. Indices count from 1. Warning Lindbladian matrices can be not diagonalizable. This functionality does not yet account for that, so it could fail in some cases. celio Keyword: celio Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: celio 10 8 Use Celio's Method instead of the regular time evolution method. The first number indicates the Trotter number, \\(k\\) , used in the expansion. The optional second number allows a number of averages to be specified enabling of approximate initial states for a drastic performance boost. This example takes \\(k = 10\\) with \\(8\\) averages. Larger values of \\(k\\) are in theory more accurate but will become inaccurate again when very large at a point depending on the system. A value of \\(k = 0\\) has no effect as it disables its use. Note Celio's method does not support dissipation or integral calculations. Method 1 - Evolving the density matrix When the number of averages is not specified or is given as 0, only the first part of Celio's method is performed to evolve the initial density matrix. This way it retains the ability to work with an initial temperature and is not subject to randomness in the results. This method will only provide a speed boost for certain systems, typically those with large spins and relatively few, simple interactions. Warning Some systems will be extremely slow using this method due to the matrix density being too high. A warning message is displayed in the '.log' file when this is the case. Method 2 - Using random initial states When the number of averages is given as a value greater than 0, random initial states will be generated for the muon and the full version of Celio's method will be run repeatedly to obtain an average. These results will be less accurate and subject to randomness but this method is substantially faster and requires less memory making it very useful for large systems. This method is also parallelised when MuSpinSim is installed with OpenMP.","title":"Input"},{"location":"input/#input","text":"The input file format for MuSpinSim is a simple text file structured using keywords and values this way: keyword additional arguments value_1 value_2 Some keywords accept additional arguments, others don't. Values are on multiple rows; in some cases multiple values can be present on the same row. The most important thing is the indent: values have to be indented with respect to the keywords, if there are no spaces at the beginning of the line then they will be read as another keyword instead. In addition, in some keywords, special functions can be used in place of lengthy lists, as well as operations instead of simple numbers. An example file is the one you can find in /examples/basic/basic.in : name basic spins mu e hyperfine 1 10 0 0 0 10 0 0 0 10 time range(0, 0.1, 100) y_axis asymmetry This defines a system of a muon and an electron, coupled by an isotropic hyperfine tensor of 10 MHz, and will save a file containing the time evolution of the muon's polarization (asymmetry) from 0 to 0.1 microseconds, in 100 steps.","title":"Input"},{"location":"input/#using-expressions-in-keyword-values","text":"One of the new features of MuSpinSim v1.0.0 is the option to use functions and variables in keyword values. These have a few uses: They can be used to access some meaningful mathematical or physical constants in place of numbers. For example, one can write 10.0*MHz as an applied magnetic field, and it will immediately be converted to the equivalent field in Tesla for an ALC resonance, as MHz = 1/(2*muon_gyr) , with the gyromagnetic ratio of the muon, muon_gyr = 135.5388 (in MHz/T). They can be used to generate large ranges of values automatically for some very common use cases. For example, the keyword time stores all the times at which the simulation should be performed. It's a common requirement to want to acquire hundreds or thousands of time points, regularly spaced. One could do this by writing hundreds or thousands of values in column, but it's a lot faster and easier to simply use something like range(0, 1, 100) to create 100 equally spaced time points going from 0 to 1 microseconds. They can be used to insert variables defined for fitting. For example one might define a hyperfine interaction tensor as a function of two parameters, then fit those parameters to find the optimal tensor that explains an experimental result. Expressions allow use of the operators + , - , * , / and ^ for exponentiation. Parentheses ( and ) can be used. Strings, if used, must be enclosed in double quotes \" . In the keyword list, below, which constants and functions are allowed for each keyword are specified. User-defined constants are currently not allowed: the only types of user-defined variables that can be used are the ones for fitting. By default, all keywords in which expressions can be used allow the following constants: pi : ratio of a circle and its diameter e : base of the natural logarithm deg : conversion factor between radians and degrees, equivalent to 180/pi inf : infinity and the following functions: sin(x) : sine cos(x) : cosine tan(x) : tangent arcsin(x) : inverse of the sine arccos(x) : inverse of the cosine arctan(x) : inverse of the tangent arctan2(y, x) : inverse of the tangent taking two arguments as (sine, cosine) to resolve the quadrant exp(x) : exponential with base e log(x) : natural logarithm sqrt(x) : square root These are all reserved names and can't be used as variable names.","title":"Using expressions in keyword values"},{"location":"input/#using-multiple-lines-for-a-keyword","text":"Some keywords accept an arbitrary amount of lines. This is different from keywords like hyperfine , that only take three lines so that the user can write a full matrix. Keywords that allow multiple rows are meant to allow the user to define ranges of values. When a range of values is defined, three things can happen: one range must always exist and will be specified as the x_axis of the system. This will be the range of values that appears on the first column of the output files. This is usually time , but it can also be, for example, field . some ranges are specified as average_axes and will be averaged over. This means that calculations will be carried for each value in these ranges and then they will all be summed over, and only the average will be printed out. A typical example of an axis to average over is orientation , to perform powder averages. any range that isn't specified in the previous two groups automatically means that the software will print out a different file for each value. When using ranges, remember that the number of calculations to perform grows very quickly with them. If one for example asked for an average over 100 different orientations, and to print out a file for each of 20 possible fields and 10 different temperatures, that would result in 100x20x10 = 20,000 individual simulations, and 20x10 = 200 files. The software doesn't have any specific safeguards against going overboard with them, but it's very easy if working on a simple desktop machine or laptop to just overwhelm its capabilities if one uses big ranges carelessly. MuSpinSim is reasonably well optimised and can be very fast for simple calculations, but complex systems and large ranges can make for very resource-intensive simulations. In the list of input keywords below, keywords that can be defined as a range are identified by the \"Allows multiple rows\" property.","title":"Using multiple lines for a keyword"},{"location":"input/#input-keywords","text":"Here is a list of accepted keywords and what they mean.","title":"Input keywords"},{"location":"input/#spins","text":"Keyword: spins Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: spins mu e 2H A list of the spins to be used in the system. This has to include a muon ( mu ) and can contain one or more electrons ( e ). If only one electron is present, it will be the one all hyperfine couplings are with by default. Atomic species refer to the nuclei; so, for example, if you're trying to model the interaction of a muon with a paramagnetic electron on an iron atom, you want to use e , not Fe ; the actual spin is that of an electron, not a nucleus! In addition, in case of multiple strongly coupled electrons that can be treated as a single spin greater than 1/2, the isotope syntax can be used too, so for example 2e represents two electrons in a triplet state, acting as a single particle with the same gyromagnetic ratio as the electron, but spin 1. The default isotope is the most common one that has a non-zero spin. Other isotopes may be specified by writing the atomic mass as an integer before the symbol. By default, this is a muon and an electron.","title":"spins"},{"location":"input/#name","text":"Keyword: name Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: name mysystem A prefix to use for all files saved in this simulation. By default it's muspinsim .","title":"name"},{"location":"input/#polarization","text":"Keyword: polarization Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, longitudinal , transverse Allows functions: default Example: polarization longitudinal The direction along which the muon should be polarized when starting, as well as the one in which it will be measured. It can be specified as a vector, and multiple values are allowed. The constants transverse and longitudinal are just useful shorthands for the X axis and the Z axis, respectively. Unless specified otherwise, the magnetic field is aligned along the Z axis. The default value is transverse .","title":"polarization"},{"location":"input/#field","text":"Keyword: field Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, MHz , muon_gyr Allows functions: default, range Example: field 0 1*MHz 2*MHz 4*MHz A single or range of external magnetic fields, in Tesla, to simulate. These can be scalars or vectors; if scalars, the field will be assumed to be aligned with the Z axis. The function range expands into a number of values - by default, 50 of them, if only the start and end are specified. The default value is zero. This field type will be affected by any orientation changes such as when doing an angular average.","title":"field"},{"location":"input/#intrinsic_field","text":"Keyword: intrinsic_field Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, MHz , muon_gyr Allows functions: default, range Example: intrinsic_field 0 1*MHz 2*MHz 4*MHz A single or range of intrinsic magnetic fields, in Tesla, to simulate. These can be scalars or vectors; if scalars, the field will be assumed to be aligned with the Z axis. The function range expands into a number of values - by default, 50 of them, if only the start and end are specified. The default value is zero. This field type will be unaffected by any orientation changes such as when doing an angular average.","title":"intrinsic_field"},{"location":"input/#time","text":"Keyword: time Allows multiple rows: Yes Allows expressions: Yes Allows constants: default Allows functions: default, range Example: time range(0, 1, 100) A time or range of times, in microseconds, to simulate. Used by default as the x_axis . The function range expands into a number of values - by default, 50 of them, if only the start and end are specified. The default value is range(0, 10, 101) .","title":"time"},{"location":"input/#x_axis","text":"Keyword: x_axis Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: x_axis field Which range to use as the X axis of the simulation's output files. Must be another keyword that accepts a range, and the given keyword must be specified as a range in this input file. When fitting, this is also assumed to be the X axis of the data to fit, and the range specified for this keyword is overridden by the fitting data. By default it's time .","title":"x_axis"},{"location":"input/#y_axis","text":"Keyword: y_axis Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: y_axis integral What to save as the Y axis of the simulation's output files: if the muon's polarization ( asymmetry ) or its integral over time, taking into account the exponential decay with the particle's half-life ( integral ). By default asymmetry , and can generally be ignored unless one is interested in Avoided Level Crossing experiments, which need integral . When set to integral , the time keyword is ignored and can not be the x_axis .","title":"y_axis"},{"location":"input/#average_axes","text":"Keyword: average_axes Allows multiple rows: Yes Allows expressions: No Allows constants: N/A Allows functions: N/A Example: average_axes orientation polarisation Any keywords that should have an average carried out over them (if they include a range of values). By default it's just orientation . Any axes with a range that aren't either x_axis or included here are automatically used for different files.","title":"average_axes"},{"location":"input/#orientation","text":"Keyword: orientation Allows multiple rows: Yes Allows expressions: Yes Allows constants: default Allows functions: default, zcw , eulrange Example: orientation zxz 45*deg 0 90*deg 1.0 90*deg 30*deg 60*deg 2.0 One or more orientations to use for the crystallites making up the system. Used to define powder averages. The rows can come in a number of ways: two numbers are interpreted as two polar angles \u03b8 and \u03d5, defining only the direction of the Z axis of the new system. This setting is recommended only for powder averages in which only the Z axis matters; typical example is an ALC calculation with both the magnetic field and the muon polarization aligned along Z. three numbers are interpreted as Euler angles defining a new frame. If there is no argument specified after orientation , the convention used is ZYZ. As seen in the example, it's possible to specify it to be ZXZ instead. four numbers are interpreted as Euler angles as above, plus one weight. The weights don't need to add up to one (they will be normalised). In this case, any average over these orientations will be weighted; otherwise, the weights will be ignored. Two helper functions are provided to generate automatically ranges of orientations for powder averages. zcw(N) creates N or more polar angle pairs using the Zaremba-Conroy-Wolfsberg algorithm to cover the sphere. It's cheap but only usable in cases in which polar angles are sufficient. eulrange(N) creates a regular grid of \\(N\\times N \\times N\\) Euler angles with appropriate weights. This covers the space of all possible orientations in 3D but can become a lot more expensive very quickly.","title":"orientation"},{"location":"input/#temperature","text":"Keyword: temperature Allows multiple rows: Yes Allows expressions: Yes Allows constants: default Allows functions: default, range Example: temperature 273.0 Temperature in Kelvin of the system. This is used to determine the initial density matrix of the system, as every spin that is not the muon is put in a thermal state, and in case of dissipative systems, to determine the coupling to the thermal bath. By default, it is set to infinity. A warning: both density matrices and dissipative couplings for finite temperatures are only calculated approximatively, based on the individual Hamiltonians for each spin which only account for the applied magnetic field. In other words, these approximations are meant for high field experiments, and break down in the low field regime. Therefore, caution should be used when changing this variable or interpreting the resulting simulations.","title":"temperature"},{"location":"input/#fitting_variables","text":"Keyword: fitting_variables Allows multiple rows: Yes Allows expressions: Yes Allows constants: default, muon_gyr , MHz Allows functions: default Example: fitting_variables x y 1.0 0.0 5.0 Variables to fit to the experimental data. If present, the calculation is assumed to be a fitting, and the fitting_data keyword must be present too. The first letter in each row is the name of the variable; optionally, it can be followed in order by the starting value of the variable, the minimum bound, and the maximum bound (by default 0 , -inf and +inf ). It is important to notice that while expressions are accepted in the definition of value, minimum, and maximum, these can not contain the name of other variables.","title":"fitting_variables"},{"location":"input/#fitting_data","text":"Keyword: fitting_data Allows multiple rows: Yes Allows expressions: Yes Allows constants: none Allows functions: load Example: fitting_data load('results.dat') Block of data to fit. Must have two columns: the first one is the x_axis (for example, time), while the second is the expected result of the simulation. The function load can be used to load it from an ASCII tabulated file on disk, as long as it has only two columns. Note that the data must be normalized properly to match the conventions of MuSpinSim's output, so for example it must start from 0.5 at t = 0 (as that's the moment of the muon before it has had any time to evolve).","title":"fitting_data"},{"location":"input/#fitting_method","text":"Keyword: fitting_method Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: fitting_method lbfgs Method to use to fit the data. Currently available are only nelder-mead (default) and lbfgs .","title":"fitting_method"},{"location":"input/#fitting_tolerance","text":"Keyword: fitting_tolerance Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: fitting_tolerance 1e-4 Tolerance for the fitting. Used as the tol parameter in Scipy's scipy.optimize.minimize method; exact meaning depends on fitting method. Check the Scipy documentation for further details.","title":"fitting_tolerance"},{"location":"input/#experiment","text":"Keyword: experiment Allows multiple rows: No Allows expressions: No Allows constants: N/A Allows functions: N/A Example: experiment alc A convenience keyword that sets a number of other parameters to reproduce certain experimental setups. Possible values are alc (sets up an Avoided Level Crossing experiment: longitudinal polarization, field as x_axis , integral as y_axis ) and zero_field (sets field as 0 and polarization as transverse ).","title":"experiment"},{"location":"input/#zeeman","text":"Keyword: zeeman Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: zeeman 1 2.0 2.0 0 Add a Zeeman coupling term specifying a local magnetic field, in Tesla, for a given spin. This coupling will be on top of the standard coupling with the external magnetic field from the laboratory, that always applies to all spins. The argument is the index of the coupled spin. Indices count from 1.","title":"zeeman"},{"location":"input/#hyperfine","text":"Keyword: hyperfine Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: hyperfine 1 100 10 10 10 100 10 10 10 100 Specify a hyperfine tensor, in MHz, for a given spin. A hyperfine tensor couples the spin with one electron in the system. If there is only one electron, then only one index can be indicated, and it's the index of the non-electron spin. If there is more than one electron in the system, more than one index must be indicated, and the second index must refer to an electron. The tensor must be written with three numbers per line. The argument (here 1 ) represents the index of the coupled spin. A second argument specifying the index of the electron is only obligatory if the system has more than one electron. Indices count from 1. Note that the block is always composed of three rows, but this is not interpreted as a range.","title":"hyperfine"},{"location":"input/#dipolar","text":"Keyword: dipolar Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: dipolar 1 2 0 1 1 Specify a dipolar coupling between two spins. This is given by a vector connecting them, in Angstrom. The coupling tensor will be then calculated based on the known gyromagnetic ratios of those spins. The two arguments are the indices of the coupled spins. Indices count from 1.","title":"dipolar"},{"location":"input/#quadrupolar","text":"Keyword: quadrupolar Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: quadrupolar 3 100 10 10 10 100 10 10 10 -200 Specify a quadrupolar coupling for a spin by using an Electric Field Gradient tensor in atomic units (as returned by for example the DFT software CASTEP). The argument is the index of the spin. The coupling will then be calculated by using the known values of angular momentum and quadrupole moment for each spin. Spins with zero quadrupole moment (like hydrogen) will have zero coupling regardless of what is specified in this term. Indices count from 1. Note that the block is always composed of three rows, but this is not interpreted as a range.","title":"quadrupolar"},{"location":"input/#dissipation","text":"Keyword: dissipation Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: dissipation 1 0.5 Add a dissipation term for a given spin, which switches the system to using the Lindblad master equation instead of regular unitary quantim evolution. The dissipative term will cause random spin flips that decohere the system and drive it towards a thermal equilibrium state (determined by the temperature). The dissipation term is given in MHz. Indices count from 1. Warning Lindbladian matrices can be not diagonalizable. This functionality does not yet account for that, so it could fail in some cases.","title":"dissipation"},{"location":"input/#celio","text":"Keyword: celio Allows multiple rows: No Allows expressions: Yes Allows constants: Default Allows functions: Default Example: celio 10 8 Use Celio's Method instead of the regular time evolution method. The first number indicates the Trotter number, \\(k\\) , used in the expansion. The optional second number allows a number of averages to be specified enabling of approximate initial states for a drastic performance boost. This example takes \\(k = 10\\) with \\(8\\) averages. Larger values of \\(k\\) are in theory more accurate but will become inaccurate again when very large at a point depending on the system. A value of \\(k = 0\\) has no effect as it disables its use. Note Celio's method does not support dissipation or integral calculations.","title":"celio"},{"location":"input/#method-1-evolving-the-density-matrix","text":"When the number of averages is not specified or is given as 0, only the first part of Celio's method is performed to evolve the initial density matrix. This way it retains the ability to work with an initial temperature and is not subject to randomness in the results. This method will only provide a speed boost for certain systems, typically those with large spins and relatively few, simple interactions. Warning Some systems will be extremely slow using this method due to the matrix density being too high. A warning message is displayed in the '.log' file when this is the case.","title":"Method 1 - Evolving the density matrix"},{"location":"input/#method-2-using-random-initial-states","text":"When the number of averages is given as a value greater than 0, random initial states will be generated for the muon and the full version of Celio's method will be run repeatedly to obtain an average. These results will be less accurate and subject to randomness but this method is substantially faster and requires less memory making it very useful for large systems. This method is also parallelised when MuSpinSim is installed with OpenMP.","title":"Method 2 - Using random initial states"},{"location":"installation/","text":"Installing MuSpinSim In this tutorial we'll go through the best ways to install MuSpinSim on any system of your interest. The first step is, of course, procuring Python itself. If you have not already done this, see the tutorial here . Installing with pip or conda Using either pip or conda will take care of installing all of the dependencies (other packages that muspinsim needs to run). Assuming you already have Python and pip installed on your system, then installing muspinsim from the command line is easy using pip install muspinsim --user or if you are using Anaconda, you may also use conda install muspinsim and you'll be ready to go. You do not need to worry about the details on the reset of this page unless the above failed, or you wish to install from the source. Installing from source To install from source you first need to ensure you have a suitable C++ compiler on your system. If you are on Linux or macOS, this is likely already the case, but for Windows you will likely need to install one such as MSCV . After this you should obtain the source from GitHub in one of two ways. If you have git installed and are familiar with its use you can simply clone the repository: git clone https://github.com/muon-spectroscopy-computational-project/muspinsim.git Otherwise, you can download it as a zip file and unzip it in a folder of your choice. To install the downloaded source, navigate to the parent directory in your terminal. If you don't know how to do it, here's a handy guide for Linux and MacOS and here's one for Windows , which has a different syntax. Once you are in the directory above the unzipped/cloned package, you can run: pip install ./{package} --user where {package} represents the name of the directory where you unzipped/cloned the package. In your case, if you didn't rename the unzipped directory, it should be: pip install ./muspinsim --user Compiling with OpenMP If installing using pip or conda , then parallelisation with OpenMP will be enabled. If compiling from source, to allow parallelisation you can assign the environment variable MUSPINSIM_WITH_OPENMP prior to installation. To do this on Linux and macOS you may use export MUSPINSIM_WITH_OPENMP=1 and for Windows set MUSPINSIM_WITH_OPENMP=1 Important While the default compiler on Linux and most Windows compilers support OpenMP, the default compiler on macOS does not. As a result you should install a compatible compiler first. We recommend using clang from homebrew's llvm package which can be installed via brew install llvm Then you need to add the following environment variables to point to the the new compilers instead of the default. The paths may differ for your system but are usually export CC=\"/usr/local/opt/llvm/bin/clang\" export CXX=\"/usr/local/opt/llvm/bin/clang++\" With these set, you can now install the downloaded source with pip install ./muspinsim --user For developers: You may also use python setup.py --with-openmp build_ext --inplace to compile the source with OpenMP while developing.","title":"Installation"},{"location":"installation/#installing-muspinsim","text":"In this tutorial we'll go through the best ways to install MuSpinSim on any system of your interest. The first step is, of course, procuring Python itself. If you have not already done this, see the tutorial here .","title":"Installing MuSpinSim"},{"location":"installation/#installing-with-pip-or-conda","text":"Using either pip or conda will take care of installing all of the dependencies (other packages that muspinsim needs to run). Assuming you already have Python and pip installed on your system, then installing muspinsim from the command line is easy using pip install muspinsim --user or if you are using Anaconda, you may also use conda install muspinsim and you'll be ready to go. You do not need to worry about the details on the reset of this page unless the above failed, or you wish to install from the source.","title":"Installing with pip or conda"},{"location":"installation/#installing-from-source","text":"To install from source you first need to ensure you have a suitable C++ compiler on your system. If you are on Linux or macOS, this is likely already the case, but for Windows you will likely need to install one such as MSCV . After this you should obtain the source from GitHub in one of two ways. If you have git installed and are familiar with its use you can simply clone the repository: git clone https://github.com/muon-spectroscopy-computational-project/muspinsim.git Otherwise, you can download it as a zip file and unzip it in a folder of your choice. To install the downloaded source, navigate to the parent directory in your terminal. If you don't know how to do it, here's a handy guide for Linux and MacOS and here's one for Windows , which has a different syntax. Once you are in the directory above the unzipped/cloned package, you can run: pip install ./{package} --user where {package} represents the name of the directory where you unzipped/cloned the package. In your case, if you didn't rename the unzipped directory, it should be: pip install ./muspinsim --user","title":"Installing from source"},{"location":"installation/#compiling-with-openmp","text":"If installing using pip or conda , then parallelisation with OpenMP will be enabled. If compiling from source, to allow parallelisation you can assign the environment variable MUSPINSIM_WITH_OPENMP prior to installation. To do this on Linux and macOS you may use export MUSPINSIM_WITH_OPENMP=1 and for Windows set MUSPINSIM_WITH_OPENMP=1 Important While the default compiler on Linux and most Windows compilers support OpenMP, the default compiler on macOS does not. As a result you should install a compatible compiler first. We recommend using clang from homebrew's llvm package which can be installed via brew install llvm Then you need to add the following environment variables to point to the the new compilers instead of the default. The paths may differ for your system but are usually export CC=\"/usr/local/opt/llvm/bin/clang\" export CXX=\"/usr/local/opt/llvm/bin/clang++\" With these set, you can now install the downloaded source with pip install ./muspinsim --user For developers: You may also use python setup.py --with-openmp build_ext --inplace to compile the source with OpenMP while developing.","title":"Compiling with OpenMP"},{"location":"theory_1/","text":"Theory of spin dynamics - I Introduction Spin is an essentially quantum mechanical phenomenon. While single spins can sometimes be usefully visualised in a classical way, as dipoles with a definite direction that are subject to rotation by precession under applied fields, this classical description quickly breaks down when multiple coupled spins are involved - and that is the premise of any and all mildly interesting muon science experiments. So, there's very little way out of the fact that muon experiments have to be described with quantum mechanical equations. Here we're going to give a quick overview of the relevant equations, their meaning, and the matrix formalism that is used to implement them numerically in MuSpinSim. The basics: spin states and Hamiltonians Spin states as vectors Quantum mechanics is often taught first with an eye to particles, like electrons, which are described by a complex-valued wavefunction \\(\\psi(x)\\) all across the three-dimensional space. The value of the wave function at a point corresponds to the amplitude of finding the particle at that point. Quantum amplitudes act like probabilities, in the sense that their square modulus \\(\\psi^*\\psi\\) expresses the probability of finding the particle at that specific point, but being complex numbers have the peculiar property that they can interfere with themselves constructively or destructively, leading to many of quantum mechanics' most counter-intuitive results (such as the way an electron's probability amplitudes add up to fringes in the double slit experiment). When it comes to individual spins, the situation is not that different, except for the fact that the wavefunction is not defined over an infinite amount of points in \\(\\mathbb{R}^3\\) ; instead, it is defined over a discrete number of states that the spin can occupy. Specifically, for a particle with spin \\(S\\) , there are \\(2S+1\\) possible states. In the simplest case, a spin-\u00bd particle, there are just two possible states: up, \\(\\mid\\uparrow\\rangle\\) and down, \\(\\mid\\downarrow\\rangle\\) . For this reason, a spin-\u00bd particle can also be considered a \"quantum bit\", or qubit . Electrons, muons and protons (namely, hydrogen nuclei) are all spin-\u00bd particles. The wavefunction of a spin-\u00bd particle can therefore be expressed with just two complex coefficients: \\[ \\mid\\psi_{1/2}\\rangle = a\\mid\\uparrow\\rangle + b\\mid\\downarrow\\rangle \\] with \\(a^*a+b^*b = 1\\) as a normalisation condition. One possible convention to write this wavefunction and manipulate it in a computer program is to treat these states as the basis for a vector space (which effectively, they are: they obey the same inner product rules as the versors for a regular Euclidean 2D space). Then we can write the wavefunction as a column vector: \\[ \\mid\\uparrow\\rangle = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\qquad \\mid\\downarrow\\rangle = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\qquad \\mid\\psi_{1/2}\\rangle = \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\] Conversely, we can write the complex conjugate versions of these states (the \"bras\" to these \"kets\") as row vectors: \\[ \\langle\\uparrow\\mid = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\qquad \\langle\\downarrow\\mid = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\qquad \\langle\\psi_{1/2}\\mid = \\begin{bmatrix} a^* & b^* \\end{bmatrix} \\] (where of course it's important to remember that the coefficients too are to be conjugated). That way, one can see for example how the inner product results naturally as a scalar product between vectors. Operators as matrices If we are describing spin states as vectors, operators can be described as matrices instead. In particular, for the spin-\u00bd particle, we have the Pauli matrices: \\[ S_x = \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix} \\qquad S_y = \\begin{bmatrix} 0 & -\\frac{i}{2} \\\\ \\frac{i}{2} & 0 \\end{bmatrix} \\qquad S_z = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & -\\frac{1}{2} \\end{bmatrix} \\] for the three spatial components of the spin. Together with the identity matrix, these form a complete basis for the operators for this kind of spin. These operators can be easily used to compute expectation values. For example, consider the following state: \\[ \\psi = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} \\] We can find the expectation values of its components by applying simple matrix product rules: \\[ \\langle S_x \\rangle = \\langle\\psi\\mid S_z \\mid\\psi\\rangle = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix}\\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{1}{4}i \\\\ \\frac{\\sqrt{3}}{4} \\end{bmatrix} = 0 \\] \\[ \\langle S_y \\rangle = \\langle\\psi\\mid S_z \\mid\\psi\\rangle = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} 0 & -\\frac{i}{2} \\\\ \\frac{i}{2} & 0 \\end{bmatrix} \\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{1}{4} \\\\ \\frac{\\sqrt{3}}{4}i \\end{bmatrix} = \\frac{\\sqrt{3}}{4} \\] \\[ \\langle S_z \\rangle = \\langle\\psi\\mid S_z \\mid\\psi\\rangle = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & -\\frac{1}{2} \\end{bmatrix} \\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{\\sqrt{3}}{4} \\\\ -\\frac{1}{4}i \\end{bmatrix} = \\frac{1}{4} \\] We can learn a few things from it. The three expectation values along x, y, z would correspond, classically, to the three components of the spin's magnetic moment. In classical terms, this would be a vector making a \\(60\u00b0\\) angle with the vertical, pointing towards the y direction. In general this example shows two important features of spin-\u00bd states: the component along z of the moment is determined by the relative probabilities of finding the spin up or down. If the probability are equal, the component along z is zero; the component in the xy plane can only be non-zero if the spin exists in some mixture of up and down states, and it's maximum if the up and down states have amplitudes with the same modulus. The specific direction of the component is then controlled by the relative phase of those amplitudes. For developers : quantum operators are defined by the class Operator and derived classes in muspinsim/spinop.py . Hamiltonian and time evolution Hamiltonians are operators with the additional required property of being Hermitian , that is, they have to be identical to their conjugate transpose. For a spin system, the Hamiltonian is the operator whose expectation value is the energy of that system. The Hamiltonian also controls the time evolution of the system; like for every other quantum system, the dynamics of a spin system are defined by the equation \\[ H\\mid\\psi\\rangle = i\\hbar\\frac{\\partial}{\\partial t}\\mid\\psi\\rangle, \\] whose solution is \\[ \\mid \\psi(t) \\rangle = e^{-\\frac{i}{\\hbar}Ht} \\mid \\psi(0) \\rangle. \\] The key task of MuSpinSim is to solve this equation in time, and then estimate the expectation values of the observables that interest us. The simplest way to do so in the case of a small system is to diagonalise the Hamiltonian, which numerically can be done fairly easily by taking advantage of its properties (for example using the NumPy routine numpy.linalg.eigh ). This gives a number of eigenvalues \\(\\lambda_i\\) and corresponding eigenvectors (namely, eigenstates) \\(\\mid u_i \\rangle\\) . One can then write the Hamiltonian matrix as: \\[ H = \\sum_i \\lambda_i \\mid u_i \\rangle \\langle u_i \\mid = UH_0U^\\dagger \\] where \\(H_0\\) is a diagonal matrix with the eigenvalues along its diagonal, and \\(U\\) is the matrix with the eigenvectors for columns (and \\(U^\\dagger\\) its conjugate transpose). One can then transform the wavefunction in this new basis, and the matrix exponential of the now diagonal Hamiltonian becomes trivial. For developers: the Hamiltonian class is a mixin inheriting from Operator and Hermitian and is found in muspinsim/hamiltonian.py . The density matrix formalism Until here we've focused on wave functions as a way to write quantum states. However, in practice, in MuSpinSim we never use simple wave functions to express the state of a system - rather, we use density matrices . The density matrix formalism is a generalisation of the state vectors we described above that allows us to describe statistical ensembles of quantum states, rather than just individual pure states. Density matrices are especially useful and important when dealing with spin systems at a thermal equilibrium, which is what makes them so essential in MuSpinSim, as any spin other than the muon itself is usually in a thermal state at the beginning of the experiment. The density matrix is an operator whose expectaction value with a certain state is the probability to find the system in that state. For a pure state in a spin-\u00bd system as the one described above, the density matrix would be \\[ \\rho = a^*a \\mid \\uparrow \\rangle \\langle \\uparrow \\mid + a^*b \\mid \\downarrow \\rangle \\langle \\uparrow \\mid + b^*a \\mid \\uparrow \\rangle \\langle \\downarrow \\mid + b^*b \\mid \\downarrow \\rangle \\langle \\downarrow \\mid = \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\begin{bmatrix} a^* & b^* \\end{bmatrix} = \\begin{bmatrix} a^*a & b^*a \\\\ a^*b & b^*b \\end{bmatrix}. \\] This type of product between vectors is called the outer product . One can see how the normalisation rule implies that \\(\\mathrm{Tr}(\\rho) = 1\\) . The expectation value of an operator can be found \\[ \\langle O \\rangle = \\mathrm{Tr}(\\rho O) \\] and the time evolution is \\[ \\frac{\\partial \\rho}{\\partial t} = -\\frac{i}{\\hbar}[H, \\rho] \\qquad\\implies\\qquad \\rho(t) = e^{-\\frac{i}{\\hbar}Ht}\\rho(0)e^{\\frac{i}{\\hbar}Ht}. \\] To see an example of the usefulness of density matrices, let's consider again a spin-\u00bd example. Consider an ensemble of particles prepared such that half of them is prepared in a state \\(\\psi_+\\) and the other half in a state \\(\\psi_-\\) : \\[ \\mid\\psi_+\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ \\frac{\\sqrt{2}}{2} \\end{bmatrix} \\qquad \\mid\\psi_-\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ \\frac{-\\sqrt{2}}{2} \\end{bmatrix}. \\] Now imagine taking a measurement of the spin along the x axis. Using the formulas above, we can discover \\(\\langle \\psi_+ \\mid S_x \\mid \\psi_+ \\rangle = 1/2\\) and \\(\\langle \\psi_- \\mid S_x \\mid \\psi_- \\rangle = -1/2\\) , so that the total average measured spin will be 0. What if we used a density matrix? Then we would find out: \\[ \\rho_+ = \\mid \\psi_+ \\rangle \\langle \\psi_+ \\mid = \\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix} \\qquad \\rho_- = \\mid \\psi_- \\rangle \\langle \\psi_- \\mid = \\begin{bmatrix} \\frac{1}{2} & -\\frac{1}{2} \\\\ -\\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}. \\] Because equations involving the density matrix are linear, we can carry out the average immediately and finding a collective density matrix describing the whole ensemble (something that is not possible with the individual wavefunctions): \\[ \\rho_{tot} = \\frac{\\rho_++\\rho_-}{2} = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix}. \\] This density matrix describes a mixed state, as it can not be expressed as the outer product of any vector with itself. We can then compute the expectation value of the operator \\(S_x\\) : \\[ \\langle S_x \\rangle = \\mathrm{Tr}(\\rho_{tot} S_x) = 0. \\] This is a very simple example of decoherence - because we are measuring a statistical ensemble of quantum systems, rather than a single spin, some information on the phase factors of its wavefunctions (the off-diagonal terms of the density matrix) can be averaged out and lost. In real life we almost never observe spins in isolations, and spin ensembles that have had a long time to exchange energy with their environment and all its random thermal fluctuations are highly decohered, as each individual spin has had its own dynamical history. This is effectively the case for the spins one usually finds inside a sample when performing a muon spin resonance experiment. For this reason we need to use density matrices when dealing with systems that have been initialised in a thermal state, as well as when trying to approximate the interaction of an open quantum system with its surrounding environment, exchanging energy with it and thus relaxing towards a thermal state. For developers: the DensityOperator class inherits from Operator and is found in muspinsim/spinop.py . Systems of multiple spins Combining spin states Systems of only one spin are not very interesting for our purposes. A lot of muon spin resonance experiments involve some kind of interaction - either hyperfine interaction between a muon and an electron in a radical, or hyperfine mediated interaction between the muon and another atomic nucleus (like hydrogen), or dipolar interaction, and so on. To see how we build such a compound state, let's consider the case of an electron and a muon, two spin-\u00bd particles. If each particle is described on a basis of \\(\\mid \\uparrow \\rangle\\) and \\(\\mid \\downarrow \\rangle\\) , then the combined system has four possible states, corresponding to all permutations of individual states: \\(\\mid \\uparrow \\uparrow \\rangle\\) , \\(\\mid \\uparrow \\downarrow \\rangle\\) , \\(\\mid \\downarrow \\uparrow \\rangle\\) and \\(\\mid \\downarrow \\downarrow \\rangle\\) . In general, a system of \\(N\\) spin-\u00bd particles will have \\(2^N\\) possible states. If the two spins were prepared independently in their own state, the state of the combined system can be built using the so-called Kronecker product between vectors: \\[ \\mid\\psi_{\\mu}\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ \\frac{\\sqrt{2}}{2} \\end{bmatrix} \\qquad \\mid\\psi_{e}\\rangle = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\qquad \\mid\\psi_{\\mu,e}\\rangle = \\mid\\psi_{\\mu}\\rangle \\otimes \\mid\\psi_{e}\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2}\\cdot \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\\\ \\frac{\\sqrt{2}}{2}\\cdot \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ 0 \\\\ \\frac{\\sqrt{2}}{2} \\\\ 0 \\end{bmatrix} \\] In this convention, we say the index of the electron states updates faster (moving down the column vector we change electron state more rapidly than we do muon states). Of course, it would be possible to also decide for the opposite convention and have the index of the muon states be the faster ones - it does not matter as long as we keep our convention consistent throughout all the calculations that follow. The same exact approach can be used for density matrices too. Consider the following state, describing a muon polarised along x and an unpolarised electron. This is a typical starting state to use for muon spin dynamics simulations: \\[ \\rho_\\mu = \\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix} \\qquad \\rho_e = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} \\] \\[ \\rho_{\\mu,e} = \\rho_{\\mu}\\otimes \\rho_{e} = \\begin{bmatrix} \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} & \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} \\\\ \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} & \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{4} & 0 & \\frac{1}{4} & 0 \\\\ 0 & \\frac{1}{4} & 0 & \\frac{1}{4} \\\\ \\frac{1}{4} & 0 & \\frac{1}{4} & 0 \\\\ 0 & \\frac{1}{4} & 0 & \\frac{1}{4} \\end{bmatrix} \\] Any state built by Kronecker product of two individual states will have the particles acting effectively independently from one another. This is not always the case. Evolution under an Hamiltonian that couples two spins will produce correlations between them. Consider the following vector state: \\[ \\mid \\psi_{corr} \\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ 0 \\\\ 0 \\\\ \\frac{\\sqrt{2}}{2} \\end{bmatrix} \\] In this state, the values measured on one particle depend on those measured on the other - either they're both up, or they're both down. This is an example of a state that can not be obtained by simply multiplying together two single particle states, because it's an example of entanglement . For developers: all classes inheriting from Operator have a .kron() method that allows Kronecker products with other operators, which will internally keep track of the dimensions of the system in order to check for compatibility in any subsequent operations. Combining operators We've seen in the previous section how to combine multiple density matrices. Since density matrices are operators, it should be clear that the rules for combining operators are exactly the same, using the Kronecker product of individual matrices. For example, a term \\(S_z^\\mu S_x^e\\) in matrix form will be: \\[ S_z^\\mu S_x^e = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & -\\frac{1}{2} \\end{bmatrix} \\otimes \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix} = \\begin{bmatrix} 0 & \\frac{1}{4} & 0 & 0 \\\\ \\frac{1}{4} & 0 & 0 & 0 \\\\ 0 & 0 & 0 &-\\frac{1}{4} \\\\ 0 & 0 &-\\frac{1}{4} & 0 \\end{bmatrix} \\] Sometimes, even in a system with multiple spins, operators involving only one of them, like \\(S_x^\\mu\\) , might be relevant. In that case we must understand them as having an implicit identity matrix for all the spins that don't appear explicitly. So we have: \\[ S_x^\\mu = S_x^\\mu\\mathbb{1}^e = \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 & \\frac{1}{2} & 0 \\\\ 0 & 0 & 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 & 0 & 0 \\\\ 0 & \\frac{1}{2} & 0 & 0 \\\\ \\end{bmatrix} \\] Spin-spin couplings All spin resonance experiments are driven by interactions between the muon and other spins. These interactions can have different nature, but are generally described by tensors. In MuSpinSim, one can either input these tensors in (as calculated with an ab initio software, for example), or run a fitting routine to try and infer them from the results of an experiment. These tensors describe an interaction in space , and thus are always \\(3\\times 3\\) matrices. How does one build these coupling terms with the formalism we're using? Let's consider a simple case: an electron and a muon coupled by a hyperfine tensor \\(\\mathbf{A}\\) in zero external magnetic field. The Hamiltonian is then calculated as follows: \\[ \\begin{split} \\mathcal{H} = & \\mathbf{S}^\\mu\\mathbf{A}\\mathbf{S}^e = \\begin{bmatrix} S^\\mu_x & S^\\mu_y & S^\\mu_z \\end{bmatrix} \\begin{bmatrix} A_{xx} & A_{xy} & A_{xz} \\\\ A_{xy} & A_{yy} & A_{yz} \\\\ A_{xz} & A_{yz} & A_{zz} \\end{bmatrix} \\begin{bmatrix} S^e_x \\\\ S^e_y \\\\ S^e_z \\end{bmatrix} \\\\ = & A_{xx}S^\\mu_xS^e_x + A_{yy}S^\\mu_yS^e_y + A_{zz}S^\\mu_zS^e_z + \\\\ +&A_{xy}(S^\\mu_xS^e_y+S^\\mu_yS^e_x) + A_{xz}(S^\\mu_xS^e_z+S^\\mu_zS^e_x) + A_{yz}(S^\\mu_yS^e_z+S^\\mu_zS^e_y) \\end{split} \\] In other words, it is a sum of operators as the ones described above. If the spin system included more spins than just the muon and electron, those would have to be implicitly included too as identity matrices in the Kronecker products. In the case of a two spin system, the final sum can be seen as a sum of \\(4 \\times 4\\) matrices, whereas the vectors \\(\\mathbf{S}^\\mu\\) and \\(\\mathbf{S}^e\\) are really \"vectors of matrices\". Numerically, we would store them as \\(3\\times4\\times4\\) arrays. For developers: tensor products involving spin operators and the creation of terms like the above are handled by the InteractionTerm class and its children, found in muspinsim/spinsys.py . Next up, we'll look at how calculations are actually initialised and run in MuSpinSim .","title":"Theory of spin dynamics - I"},{"location":"theory_1/#theory-of-spin-dynamics-i","text":"","title":"Theory of spin dynamics - I"},{"location":"theory_1/#introduction","text":"Spin is an essentially quantum mechanical phenomenon. While single spins can sometimes be usefully visualised in a classical way, as dipoles with a definite direction that are subject to rotation by precession under applied fields, this classical description quickly breaks down when multiple coupled spins are involved - and that is the premise of any and all mildly interesting muon science experiments. So, there's very little way out of the fact that muon experiments have to be described with quantum mechanical equations. Here we're going to give a quick overview of the relevant equations, their meaning, and the matrix formalism that is used to implement them numerically in MuSpinSim.","title":"Introduction"},{"location":"theory_1/#the-basics-spin-states-and-hamiltonians","text":"","title":"The basics: spin states and Hamiltonians"},{"location":"theory_1/#spin-states-as-vectors","text":"Quantum mechanics is often taught first with an eye to particles, like electrons, which are described by a complex-valued wavefunction \\(\\psi(x)\\) all across the three-dimensional space. The value of the wave function at a point corresponds to the amplitude of finding the particle at that point. Quantum amplitudes act like probabilities, in the sense that their square modulus \\(\\psi^*\\psi\\) expresses the probability of finding the particle at that specific point, but being complex numbers have the peculiar property that they can interfere with themselves constructively or destructively, leading to many of quantum mechanics' most counter-intuitive results (such as the way an electron's probability amplitudes add up to fringes in the double slit experiment). When it comes to individual spins, the situation is not that different, except for the fact that the wavefunction is not defined over an infinite amount of points in \\(\\mathbb{R}^3\\) ; instead, it is defined over a discrete number of states that the spin can occupy. Specifically, for a particle with spin \\(S\\) , there are \\(2S+1\\) possible states. In the simplest case, a spin-\u00bd particle, there are just two possible states: up, \\(\\mid\\uparrow\\rangle\\) and down, \\(\\mid\\downarrow\\rangle\\) . For this reason, a spin-\u00bd particle can also be considered a \"quantum bit\", or qubit . Electrons, muons and protons (namely, hydrogen nuclei) are all spin-\u00bd particles. The wavefunction of a spin-\u00bd particle can therefore be expressed with just two complex coefficients: \\[ \\mid\\psi_{1/2}\\rangle = a\\mid\\uparrow\\rangle + b\\mid\\downarrow\\rangle \\] with \\(a^*a+b^*b = 1\\) as a normalisation condition. One possible convention to write this wavefunction and manipulate it in a computer program is to treat these states as the basis for a vector space (which effectively, they are: they obey the same inner product rules as the versors for a regular Euclidean 2D space). Then we can write the wavefunction as a column vector: \\[ \\mid\\uparrow\\rangle = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\qquad \\mid\\downarrow\\rangle = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\qquad \\mid\\psi_{1/2}\\rangle = \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\] Conversely, we can write the complex conjugate versions of these states (the \"bras\" to these \"kets\") as row vectors: \\[ \\langle\\uparrow\\mid = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\qquad \\langle\\downarrow\\mid = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\qquad \\langle\\psi_{1/2}\\mid = \\begin{bmatrix} a^* & b^* \\end{bmatrix} \\] (where of course it's important to remember that the coefficients too are to be conjugated). That way, one can see for example how the inner product results naturally as a scalar product between vectors.","title":"Spin states as vectors"},{"location":"theory_1/#operators-as-matrices","text":"If we are describing spin states as vectors, operators can be described as matrices instead. In particular, for the spin-\u00bd particle, we have the Pauli matrices: \\[ S_x = \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix} \\qquad S_y = \\begin{bmatrix} 0 & -\\frac{i}{2} \\\\ \\frac{i}{2} & 0 \\end{bmatrix} \\qquad S_z = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & -\\frac{1}{2} \\end{bmatrix} \\] for the three spatial components of the spin. Together with the identity matrix, these form a complete basis for the operators for this kind of spin. These operators can be easily used to compute expectation values. For example, consider the following state: \\[ \\psi = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} \\] We can find the expectation values of its components by applying simple matrix product rules: \\[ \\langle S_x \\rangle = \\langle\\psi\\mid S_z \\mid\\psi\\rangle = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix}\\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{1}{4}i \\\\ \\frac{\\sqrt{3}}{4} \\end{bmatrix} = 0 \\] \\[ \\langle S_y \\rangle = \\langle\\psi\\mid S_z \\mid\\psi\\rangle = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} 0 & -\\frac{i}{2} \\\\ \\frac{i}{2} & 0 \\end{bmatrix} \\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{1}{4} \\\\ \\frac{\\sqrt{3}}{4}i \\end{bmatrix} = \\frac{\\sqrt{3}}{4} \\] \\[ \\langle S_z \\rangle = \\langle\\psi\\mid S_z \\mid\\psi\\rangle = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & -\\frac{1}{2} \\end{bmatrix} \\begin{bmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2}i \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{3}}{2} & -\\frac{1}{2}i \\end{bmatrix} \\begin{bmatrix} \\frac{\\sqrt{3}}{4} \\\\ -\\frac{1}{4}i \\end{bmatrix} = \\frac{1}{4} \\] We can learn a few things from it. The three expectation values along x, y, z would correspond, classically, to the three components of the spin's magnetic moment. In classical terms, this would be a vector making a \\(60\u00b0\\) angle with the vertical, pointing towards the y direction. In general this example shows two important features of spin-\u00bd states: the component along z of the moment is determined by the relative probabilities of finding the spin up or down. If the probability are equal, the component along z is zero; the component in the xy plane can only be non-zero if the spin exists in some mixture of up and down states, and it's maximum if the up and down states have amplitudes with the same modulus. The specific direction of the component is then controlled by the relative phase of those amplitudes. For developers : quantum operators are defined by the class Operator and derived classes in muspinsim/spinop.py .","title":"Operators as matrices"},{"location":"theory_1/#hamiltonian-and-time-evolution","text":"Hamiltonians are operators with the additional required property of being Hermitian , that is, they have to be identical to their conjugate transpose. For a spin system, the Hamiltonian is the operator whose expectation value is the energy of that system. The Hamiltonian also controls the time evolution of the system; like for every other quantum system, the dynamics of a spin system are defined by the equation \\[ H\\mid\\psi\\rangle = i\\hbar\\frac{\\partial}{\\partial t}\\mid\\psi\\rangle, \\] whose solution is \\[ \\mid \\psi(t) \\rangle = e^{-\\frac{i}{\\hbar}Ht} \\mid \\psi(0) \\rangle. \\] The key task of MuSpinSim is to solve this equation in time, and then estimate the expectation values of the observables that interest us. The simplest way to do so in the case of a small system is to diagonalise the Hamiltonian, which numerically can be done fairly easily by taking advantage of its properties (for example using the NumPy routine numpy.linalg.eigh ). This gives a number of eigenvalues \\(\\lambda_i\\) and corresponding eigenvectors (namely, eigenstates) \\(\\mid u_i \\rangle\\) . One can then write the Hamiltonian matrix as: \\[ H = \\sum_i \\lambda_i \\mid u_i \\rangle \\langle u_i \\mid = UH_0U^\\dagger \\] where \\(H_0\\) is a diagonal matrix with the eigenvalues along its diagonal, and \\(U\\) is the matrix with the eigenvectors for columns (and \\(U^\\dagger\\) its conjugate transpose). One can then transform the wavefunction in this new basis, and the matrix exponential of the now diagonal Hamiltonian becomes trivial. For developers: the Hamiltonian class is a mixin inheriting from Operator and Hermitian and is found in muspinsim/hamiltonian.py .","title":"Hamiltonian and time evolution"},{"location":"theory_1/#the-density-matrix-formalism","text":"Until here we've focused on wave functions as a way to write quantum states. However, in practice, in MuSpinSim we never use simple wave functions to express the state of a system - rather, we use density matrices . The density matrix formalism is a generalisation of the state vectors we described above that allows us to describe statistical ensembles of quantum states, rather than just individual pure states. Density matrices are especially useful and important when dealing with spin systems at a thermal equilibrium, which is what makes them so essential in MuSpinSim, as any spin other than the muon itself is usually in a thermal state at the beginning of the experiment. The density matrix is an operator whose expectaction value with a certain state is the probability to find the system in that state. For a pure state in a spin-\u00bd system as the one described above, the density matrix would be \\[ \\rho = a^*a \\mid \\uparrow \\rangle \\langle \\uparrow \\mid + a^*b \\mid \\downarrow \\rangle \\langle \\uparrow \\mid + b^*a \\mid \\uparrow \\rangle \\langle \\downarrow \\mid + b^*b \\mid \\downarrow \\rangle \\langle \\downarrow \\mid = \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\begin{bmatrix} a^* & b^* \\end{bmatrix} = \\begin{bmatrix} a^*a & b^*a \\\\ a^*b & b^*b \\end{bmatrix}. \\] This type of product between vectors is called the outer product . One can see how the normalisation rule implies that \\(\\mathrm{Tr}(\\rho) = 1\\) . The expectation value of an operator can be found \\[ \\langle O \\rangle = \\mathrm{Tr}(\\rho O) \\] and the time evolution is \\[ \\frac{\\partial \\rho}{\\partial t} = -\\frac{i}{\\hbar}[H, \\rho] \\qquad\\implies\\qquad \\rho(t) = e^{-\\frac{i}{\\hbar}Ht}\\rho(0)e^{\\frac{i}{\\hbar}Ht}. \\] To see an example of the usefulness of density matrices, let's consider again a spin-\u00bd example. Consider an ensemble of particles prepared such that half of them is prepared in a state \\(\\psi_+\\) and the other half in a state \\(\\psi_-\\) : \\[ \\mid\\psi_+\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ \\frac{\\sqrt{2}}{2} \\end{bmatrix} \\qquad \\mid\\psi_-\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ \\frac{-\\sqrt{2}}{2} \\end{bmatrix}. \\] Now imagine taking a measurement of the spin along the x axis. Using the formulas above, we can discover \\(\\langle \\psi_+ \\mid S_x \\mid \\psi_+ \\rangle = 1/2\\) and \\(\\langle \\psi_- \\mid S_x \\mid \\psi_- \\rangle = -1/2\\) , so that the total average measured spin will be 0. What if we used a density matrix? Then we would find out: \\[ \\rho_+ = \\mid \\psi_+ \\rangle \\langle \\psi_+ \\mid = \\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix} \\qquad \\rho_- = \\mid \\psi_- \\rangle \\langle \\psi_- \\mid = \\begin{bmatrix} \\frac{1}{2} & -\\frac{1}{2} \\\\ -\\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}. \\] Because equations involving the density matrix are linear, we can carry out the average immediately and finding a collective density matrix describing the whole ensemble (something that is not possible with the individual wavefunctions): \\[ \\rho_{tot} = \\frac{\\rho_++\\rho_-}{2} = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix}. \\] This density matrix describes a mixed state, as it can not be expressed as the outer product of any vector with itself. We can then compute the expectation value of the operator \\(S_x\\) : \\[ \\langle S_x \\rangle = \\mathrm{Tr}(\\rho_{tot} S_x) = 0. \\] This is a very simple example of decoherence - because we are measuring a statistical ensemble of quantum systems, rather than a single spin, some information on the phase factors of its wavefunctions (the off-diagonal terms of the density matrix) can be averaged out and lost. In real life we almost never observe spins in isolations, and spin ensembles that have had a long time to exchange energy with their environment and all its random thermal fluctuations are highly decohered, as each individual spin has had its own dynamical history. This is effectively the case for the spins one usually finds inside a sample when performing a muon spin resonance experiment. For this reason we need to use density matrices when dealing with systems that have been initialised in a thermal state, as well as when trying to approximate the interaction of an open quantum system with its surrounding environment, exchanging energy with it and thus relaxing towards a thermal state. For developers: the DensityOperator class inherits from Operator and is found in muspinsim/spinop.py .","title":"The density matrix formalism"},{"location":"theory_1/#systems-of-multiple-spins","text":"","title":"Systems of multiple spins"},{"location":"theory_1/#combining-spin-states","text":"Systems of only one spin are not very interesting for our purposes. A lot of muon spin resonance experiments involve some kind of interaction - either hyperfine interaction between a muon and an electron in a radical, or hyperfine mediated interaction between the muon and another atomic nucleus (like hydrogen), or dipolar interaction, and so on. To see how we build such a compound state, let's consider the case of an electron and a muon, two spin-\u00bd particles. If each particle is described on a basis of \\(\\mid \\uparrow \\rangle\\) and \\(\\mid \\downarrow \\rangle\\) , then the combined system has four possible states, corresponding to all permutations of individual states: \\(\\mid \\uparrow \\uparrow \\rangle\\) , \\(\\mid \\uparrow \\downarrow \\rangle\\) , \\(\\mid \\downarrow \\uparrow \\rangle\\) and \\(\\mid \\downarrow \\downarrow \\rangle\\) . In general, a system of \\(N\\) spin-\u00bd particles will have \\(2^N\\) possible states. If the two spins were prepared independently in their own state, the state of the combined system can be built using the so-called Kronecker product between vectors: \\[ \\mid\\psi_{\\mu}\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ \\frac{\\sqrt{2}}{2} \\end{bmatrix} \\qquad \\mid\\psi_{e}\\rangle = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\qquad \\mid\\psi_{\\mu,e}\\rangle = \\mid\\psi_{\\mu}\\rangle \\otimes \\mid\\psi_{e}\\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2}\\cdot \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\\\ \\frac{\\sqrt{2}}{2}\\cdot \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ 0 \\\\ \\frac{\\sqrt{2}}{2} \\\\ 0 \\end{bmatrix} \\] In this convention, we say the index of the electron states updates faster (moving down the column vector we change electron state more rapidly than we do muon states). Of course, it would be possible to also decide for the opposite convention and have the index of the muon states be the faster ones - it does not matter as long as we keep our convention consistent throughout all the calculations that follow. The same exact approach can be used for density matrices too. Consider the following state, describing a muon polarised along x and an unpolarised electron. This is a typical starting state to use for muon spin dynamics simulations: \\[ \\rho_\\mu = \\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix} \\qquad \\rho_e = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} \\] \\[ \\rho_{\\mu,e} = \\rho_{\\mu}\\otimes \\rho_{e} = \\begin{bmatrix} \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} & \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} \\\\ \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} & \\frac{1}{2}\\cdot \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{2} \\end{bmatrix} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{4} & 0 & \\frac{1}{4} & 0 \\\\ 0 & \\frac{1}{4} & 0 & \\frac{1}{4} \\\\ \\frac{1}{4} & 0 & \\frac{1}{4} & 0 \\\\ 0 & \\frac{1}{4} & 0 & \\frac{1}{4} \\end{bmatrix} \\] Any state built by Kronecker product of two individual states will have the particles acting effectively independently from one another. This is not always the case. Evolution under an Hamiltonian that couples two spins will produce correlations between them. Consider the following vector state: \\[ \\mid \\psi_{corr} \\rangle = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ 0 \\\\ 0 \\\\ \\frac{\\sqrt{2}}{2} \\end{bmatrix} \\] In this state, the values measured on one particle depend on those measured on the other - either they're both up, or they're both down. This is an example of a state that can not be obtained by simply multiplying together two single particle states, because it's an example of entanglement . For developers: all classes inheriting from Operator have a .kron() method that allows Kronecker products with other operators, which will internally keep track of the dimensions of the system in order to check for compatibility in any subsequent operations.","title":"Combining spin states"},{"location":"theory_1/#combining-operators","text":"We've seen in the previous section how to combine multiple density matrices. Since density matrices are operators, it should be clear that the rules for combining operators are exactly the same, using the Kronecker product of individual matrices. For example, a term \\(S_z^\\mu S_x^e\\) in matrix form will be: \\[ S_z^\\mu S_x^e = \\begin{bmatrix} \\frac{1}{2} & 0 \\\\ 0 & -\\frac{1}{2} \\end{bmatrix} \\otimes \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix} = \\begin{bmatrix} 0 & \\frac{1}{4} & 0 & 0 \\\\ \\frac{1}{4} & 0 & 0 & 0 \\\\ 0 & 0 & 0 &-\\frac{1}{4} \\\\ 0 & 0 &-\\frac{1}{4} & 0 \\end{bmatrix} \\] Sometimes, even in a system with multiple spins, operators involving only one of them, like \\(S_x^\\mu\\) , might be relevant. In that case we must understand them as having an implicit identity matrix for all the spins that don't appear explicitly. So we have: \\[ S_x^\\mu = S_x^\\mu\\mathbb{1}^e = \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 & \\frac{1}{2} & 0 \\\\ 0 & 0 & 0 & \\frac{1}{2} \\\\ \\frac{1}{2} & 0 & 0 & 0 \\\\ 0 & \\frac{1}{2} & 0 & 0 \\\\ \\end{bmatrix} \\]","title":"Combining operators"},{"location":"theory_1/#spin-spin-couplings","text":"All spin resonance experiments are driven by interactions between the muon and other spins. These interactions can have different nature, but are generally described by tensors. In MuSpinSim, one can either input these tensors in (as calculated with an ab initio software, for example), or run a fitting routine to try and infer them from the results of an experiment. These tensors describe an interaction in space , and thus are always \\(3\\times 3\\) matrices. How does one build these coupling terms with the formalism we're using? Let's consider a simple case: an electron and a muon coupled by a hyperfine tensor \\(\\mathbf{A}\\) in zero external magnetic field. The Hamiltonian is then calculated as follows: \\[ \\begin{split} \\mathcal{H} = & \\mathbf{S}^\\mu\\mathbf{A}\\mathbf{S}^e = \\begin{bmatrix} S^\\mu_x & S^\\mu_y & S^\\mu_z \\end{bmatrix} \\begin{bmatrix} A_{xx} & A_{xy} & A_{xz} \\\\ A_{xy} & A_{yy} & A_{yz} \\\\ A_{xz} & A_{yz} & A_{zz} \\end{bmatrix} \\begin{bmatrix} S^e_x \\\\ S^e_y \\\\ S^e_z \\end{bmatrix} \\\\ = & A_{xx}S^\\mu_xS^e_x + A_{yy}S^\\mu_yS^e_y + A_{zz}S^\\mu_zS^e_z + \\\\ +&A_{xy}(S^\\mu_xS^e_y+S^\\mu_yS^e_x) + A_{xz}(S^\\mu_xS^e_z+S^\\mu_zS^e_x) + A_{yz}(S^\\mu_yS^e_z+S^\\mu_zS^e_y) \\end{split} \\] In other words, it is a sum of operators as the ones described above. If the spin system included more spins than just the muon and electron, those would have to be implicitly included too as identity matrices in the Kronecker products. In the case of a two spin system, the final sum can be seen as a sum of \\(4 \\times 4\\) matrices, whereas the vectors \\(\\mathbf{S}^\\mu\\) and \\(\\mathbf{S}^e\\) are really \"vectors of matrices\". Numerically, we would store them as \\(3\\times4\\times4\\) arrays. For developers: tensor products involving spin operators and the creation of terms like the above are handled by the InteractionTerm class and its children, found in muspinsim/spinsys.py . Next up, we'll look at how calculations are actually initialised and run in MuSpinSim .","title":"Spin-spin couplings"},{"location":"theory_2/","text":"Theory of spin dynamics - II Preparing the initial state When performing a simulation of a muon experiment, the first step is to prepare the system in an appropriate quantum state to evolve under the Hamiltonian. MuSpinSim uses the following rules to prepare this state: the muon is prepared in a state polarised along the direction of the beam (conventionally, the x axis in the laboratory frame of reference); every other spin is prepared in a thermal density matrix state. A thermal density matrix state simply means a state in which every energy level is populated with a probability following the Boltzmann distribution, and fully decohered otherwise. In other words: \\[ \\rho_{th}(T) = \\frac{e^{-\\frac{\\mathcal{H}}{k_BT}}}{\\mathrm{Tr}\\left(e^{-\\frac{\\mathcal{H}}{k_BT}}\\right)} \\] where the trace below is the partition function of the system. One can see how finding this matrix would in principle require diagonalising the Hamiltonian of the whole system the muon is being inserted in. In practice, in MuSpinSim we use one of two approximations: by default, the \\(T=\\infty\\) approximation is used, in which all states are equally populated. The advantage of this approximation is that it's completely invariant to any change of basis - it doesn't make a difference what exactly the eigenstates of the Hamiltonian are. The real temperature of the sample, of course, is not infinite, but as long as \\(k_BT \\gg \\mathcal{H}\\) , that's a fair enough approximation; if requested by the user, finite temperature can be used, but the Hamiltonian is simplified to the Zeeman Hamiltonian, \\(\\mathcal{H} \\approx \\hbar \\sum_i\\gamma_i \\mathbf{B}\\mathbf{S}^{(i)}\\) . This approximation keeps all spins independent from each other, ignoring their possible couplings, and is very effective in the case in which a strong magnetic field is applied and the Zeeman term is prevalent in the Hamiltonian. It should not be used for zero field experiment simulations. For developers: the initial density matrix is calculated in the property .rho0() of the class ExperimentRunner , found in muspinsim/experiment.py . Time evolution Closed system Time evolution for the density matrix of a closed quantum system is controlled by the Liouville-von Neumann equation that we've already seen: \\[ \\frac{\\partial \\rho}{\\partial t} = -\\frac{i}{\\hbar}[\\mathcal{H}, \\rho] \\] If we write the matrix quantities with indices (repeated indices imply summation) we can write this as a system of coupled differential equations for each individual coefficient: \\[ \\frac{\\partial \\rho_{ij}}{\\partial t} = -\\frac{i}{\\hbar}\\left(\\mathcal{H}_{ik}\\rho_{kj}-\\rho_{ik}\\mathcal{H}_{kj}\\right) \\] This gets significantly simpler when we express both the matrices in a basis in which the Hamiltonian is diagonal, and thus \\(\\mathcal{H}_{ij} = \\lambda_i\\delta_{ij}\\) : \\[ \\frac{\\partial \\rho_{ij}}{\\partial t} = -\\frac{i}{\\hbar}\\rho_{ij}\\left(\\lambda_i-\\lambda_j\\right) \\qquad \\implies \\qquad \\rho_{ij}(t) = e^{-\\frac{i}{\\hbar}\\left(\\lambda_i-\\lambda_j\\right) t}\\rho_{ij}(0) \\] This way we can see that the equations are completely decoupled. Coefficients on the diagonal of the density matrix don't change, while off-diagonal coefficients gain a phase factor at a constant rate that is dependent on the differences between the Hamiltonian eigenvalues. This method gives us the exact evolution of the system and perfectly preserves unitarity. The downside of it is that it requires a full diagonalization of the Hamiltonian. However, many spin systems that we are interested in are relatively small, and one single diagonalisation for each of them isn't a big deal. For a cheaper, more approximate method see Celio's Method . For developers: time evolution of a system is handled by the .evolve() method of the Hamiltonian class. A faster method When simulating systems where \\(\\frac{B}{T} \\rightarrow 0\\) , i.e. when we have zero external magnetic field or the temperature \\(T \\rightarrow \\infty\\) , MuSpinSim will automatically employ a faster method of time evolution. To explain this method we first note that the density matrix at \\(t=0\\) for the muon polarised along a direction \\({\\hat n}\\) can be written as \\[ \\rho_\\mu (t=0) = \\frac{1}{2}(\\mathbb{1} + \\sigma_\\mu^{\\hat n}), \\] and hence the density matrix of the full system is, (defining \\(d =\\prod_{i \\neq 0} 2I_i + 1\\) as the dimension of the Hilbert space without the muon) \\[ \\rho(t=0) = \\frac{1}{2}(\\mathbb{1}+\\sigma_\\mu^{\\hat n}) \\otimes \\frac{1}{d}\\mathbb{1}_d. \\] Here we want to calculate the time dependence of the muon polarisation along \\({\\hat n}\\) , which is given by (notational abuse means \\(\\sigma_\\mu^{\\hat n}(t) = e^{-\\frac{i}{\\hbar}Ht}(\\sigma_\\mu^{\\hat n} \\otimes \\mathbb{1}_d) e^{\\frac{i}{\\hbar}Ht}\\) ) \\[ P^{\\hat n}_\\mu(t) = \\mathrm{Tr}[\\rho(t)\\sigma_\\mu^{\\hat n}(0)] = \\mathrm{Tr}[\\rho(t=0)\\sigma_\\mu^{\\hat n}(t)]. \\] We have also switched which operator we are time-evolving on the RHS here. Now, substituting \\(\\rho(t=0)\\) , we get \\[ P^{\\hat n}_\\mu(t) = \\mathrm{Tr}[\\rho(t=0)\\sigma_\\mu^{\\hat n}(t)]= \\mathrm{Tr}\\Bigg[\\Big(\\frac{1}{2}(\\mathbb{1}+\\sigma_\\mu^{\\hat n}) \\otimes \\frac{1}{d}\\mathbb{1}_{d} \\Big)\\sigma_\\mu^{\\hat n}(t)\\Bigg] \\] which can be simplified to \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\mathrm{Tr}\\Bigg[\\Big((\\mathbb{1}+\\sigma_\\mu^{\\hat n}) \\otimes \\mathbb{1}_{d} \\Big)\\sigma_\\mu^{\\hat n}(t)\\Bigg]. \\] Now, if we factor out the first term in the trace, we get \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\mathrm{Tr}[(\\mathbb{1} \\otimes \\mathbb{1}_{d}) \\sigma_\\mu^{\\hat n}(t)] +\\frac{1}{2d}\\mathrm{Tr}\\Bigg[(\\sigma_\\mu^{\\hat n} \\otimes \\mathbb{1}_{d}) \\sigma_\\mu^{\\hat n}(t)\\Bigg]. \\] Note that ass the trace of a Pauli spin matrix is always zero, only the second term is non-zero. Hence the muon polarisation can be written as (after re-defining \\(\\sigma_\\mu^{\\hat n}\\) to include the kronecker product with the identity matrix of the other spins) \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\mathrm{Tr}\\Bigg[\\sigma_\\mu^{\\hat n}(0) \\sigma_\\mu^{\\hat n}(t)\\Bigg]. \\] Now replacing the trace with \\(\\sum_\\alpha \\langle \\alpha| ... | \\alpha \\rangle\\) , where \\(| \\alpha \\rangle\\) is a complete set of orthonormal eigenstates we obtain \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_\\alpha \\langle \\alpha | \\Bigg[\\sigma_\\mu^{\\hat n}(0) \\sigma_\\mu^{\\hat n}(t)\\Bigg] | \\alpha \\rangle. \\] Explicitly writing out the time dependance, we get \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha, \\beta, \\gamma} \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle e^{iE_\\beta t} \\langle \\beta | \\sigma_\\mu^{\\hat n}(0) |\\gamma \\rangle e^{-iE_\\gamma t} \\langle \\gamma | \\alpha \\rangle, \\] and as \\(\\langle \\gamma | \\alpha \\rangle = \\delta_{\\gamma, \\alpha}\\) , this simplifies to \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha, \\beta} \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle e^{iE_\\beta t} \\langle \\beta | \\sigma_\\mu^{\\hat n}(0) |\\alpha \\rangle e^{-iE_\\alpha t}, \\] so that \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha, \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t}. \\] Then, we can separate these terms into \\[ \\begin{aligned} P^{\\hat n}_\\mu(t) & = \\frac{1}{2d}\\sum_{\\alpha = \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t} \\\\ & + \\frac{1}{2d}\\sum_{\\alpha < \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t} + \\frac{1}{2d}\\sum_{\\alpha > \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t}. \\end{aligned} \\] Now by swapping \\(\\alpha\\) and \\(\\beta\\) in the last term, we see that it is the same as the second term apart from a sign in the exponential, so they may combined to give \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha = \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t} + \\frac{1}{2d}\\sum_{\\alpha < \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 [e^{i(E_\\beta-E_\\alpha) t} + e^{-i(E_\\beta-E_\\alpha) t}]. \\] Finally, by expressing the exponentials in terms of \\(\\sin\\) and \\(\\cos\\) , we may simplify the expression to \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha = \\beta}\\Big|\\langle\\alpha|\\sigma_{\\mu}^{\\hat{n}}|\\beta\\rangle\\Big|^2 + \\frac{1}{d}\\sum_{\\alpha < \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 \\cos [(E_\\beta-E_\\alpha) t]. \\] When installed with OpenMP, MuSpinSim will parallelise this method over the time values, so when computing for 100 times, it will run on up to 100 threads. For developers: this time evolution of a system is handled by the .fast_evolve() method of the Hamiltonian class. Celio's Method MuSpinSim can also make use of an approximation to speedup calculations and reduce memory usage in certain cases using Celio's method . To do this we first split up the Hamiltonian into contributions from each interaction. \\[ H = \\sum_{i}^{N} H_i \\] Then referring back to the earlier result \\[ \\rho(t) = e^{-\\frac{i}{\\hbar}Ht}\\rho(0)e^{\\frac{i}{\\hbar}Ht}. \\] We expand using the Suzuki\u2013Trotter formula \\[ e^{H_1 + H_2} = \\lim_{k\\rightarrow\\infty}{\\left[e^{\\frac{H_1}{k}}e^{\\frac{H_2}{k}}\\right]^k} \\] To obtain \\[ e^{-\\frac{i}{\\hbar}Ht} = \\lim_{k\\rightarrow\\infty}{\\left[\\prod_{i}^{N}e^{-\\frac{i}{k\\hbar}H_it}\\right]^k} \\] This allows us to compute the evolution operator while avoiding the diagonalisation of the Hamiltonian. In reality this formula is a simplification as each \\(H_i\\) acts in a smaller subspace of dimension determined by the spins involved in the interaction it describes. As a result, in computing this product in terms of matrices, we must also do the kronecker product with identity matrices that match the dimensions of the other particles in the system. We also use swap gates to ensure the order of these kronecker products is preserved. As an example, taking system of a muon and two electrons (labelled 1, 2 and 3 respectively) with a single dipolar interaction defined between the muon and second electron we compute \\[ e^{-\\frac{i}{\\hbar}Ht} = \\lim_{k\\rightarrow\\infty}{\\left[\\text{SWAP}_{32} \\left( \\mathbb{1}_2 \\otimes e^{-\\frac{i}{k\\hbar}H_{13}t}\\right)\\right]^k} \\] Where \\(H_{12}\\) is the contribution from the dipolar interaction and \\(\\mathbb{1}_2\\) is the identity matrix of size \\(2I + 1 = 2\\) (For the first electron). \\(\\text{SWAP}_{32}\\) is a swap gate that has the effect of reversing the kronecker products into the correct order and is required since \\(H_{13}\\) is formed in a subspace with only particles 1 and 3 whereas it should be computed for the system with particles 1, 2 and 3 in that order. Due to the extra matrix products this method is most suitable when the evolution operator's matrix is sparse for which it will be faster and will use significantly less memory. This will generally be the case for larger spins with a few simple interactions. MuSpinSim will log a warning in its output if the sparsity doesn't appear suitable for this variant Celio's method. Further speedup For a further speedup we can continue to follow Celio's method, approximating the initial state of the system provided that \\(T\\rightarrow \\infty\\) and use this to provide a large increase in performance. This method is also less susceptible to matrices becoming dense allowing the evolution of more complex systems but with a lower accuracy. Here instead of evolving the density matrix, we instead evolve \\(\\sigma_{\\mu}=2I_{\\mu}\\) which are the Pauli matrices in the direction of the muon. \\[ \\sigma_{\\mu}(t) = e^{-\\frac{i}{\\hbar}Ht}\\sigma_{\\mu}e^{\\frac{i}{\\hbar}Ht} \\] Then by choosing a representation where \\(\\sigma_{\\mu}\\) is diagonal we can write the muon polarisation as \\[ P(t) = \\sum_{n=1}^{d}{w_n\\bra{\\psi_n(t)}\\sigma_{\\mu}\\ket{\\psi_n(t)}} \\] where d is the total dimension of the system and \\[ \\ket{\\psi_n(t)} = e^{\\frac{-iHt}{\\hbar}}\\ket{\\psi_n(0)} \\] gives the time evolution of the initial approximated states. The coefficients \\(w_n\\) here describe the probability of finding the spin system in the state \\(\\ket{\\psi_n(0)}\\) at \\(t = 0\\) . In standard experimental conditions these are determined as \\[ w_n = \\frac{2}{d}\\text{ if }\\sigma_{\\mu}\\ket{\\psi_n(0)} = + \\ket{\\psi_n(0)} \\] \\[ w_n = 0\\text{ if }\\sigma_{\\mu}\\ket{\\psi_n(0)} = - \\ket{\\psi_n(0)} \\] Thus we can diagonalise the density matrix for the muon given by \\[ \\rho = \\mathbb{1}_2 + \\sigma_{\\mu} \\] and choose the eigenvector with a positive eigenvalue to obtain the initial state \\(\\ket{\\psi(0)}\\) Now we define the total initial state of the system as \\[ \\ket{\\phi(0)} = \\sum_{m=1}^{d/2}\\left(\\frac{2}{d}\\right)^{1/2}e^{i\\lambda_m}\\ket{\\psi_m(0)} \\] where \\(\\lambda_m\\) is chosen randomly in the range \\([0, 2\\pi]\\) . Then the state at a later time t is given by \\[ \\ket{\\phi(t)} = \\sum_{m=1}^{d/2}\\left(\\frac{2}{d}\\right)^{1/2}e^{i\\lambda_m}\\ket{\\psi_m(t)} \\] and the matrix elements are given by \\[ \\bra{\\phi(t)}\\sigma_{\\mu}\\ket{\\phi(t)} = \\sum_{m=1}^{d/2}\\frac{2}{d}\\bra{\\psi_m(t)}\\sigma_{\\mu}\\ket{\\psi_m(t)} + \\sum_{m,n=1, m\\neq n}^{d/2}\\frac{2}{d}e^{i(\\lambda_m - \\lambda_n)}\\bra{\\psi_n(t)}\\sigma_{\\mu}\\ket{\\psi_m(t)} \\] This second term vanishes for very large \\(d\\) allowing us to avoid very large matrix products which speeds up the method drastically. When installed with OpenMP, MuSpinSim will parallelise this method over the values of \\(m\\) . For developers: time evolution of a system using Celio's method is handled by the .evolve() and .fast_evolve() methods of the CelioHamiltonian class. Integral of asymmetry In muon experiments we're usually interested in measuring the asymmetry of positron hits between the forward and back detectors in the experimental setup - namely, the polarisation of the muon along a certain axis, as it evolves in time. However, in some cases (like ALC experiments) what we actually care about is the integral of this asymmetry throughout a certain time interval. This could be trivially computed simply by computing the time evolution and then integrating numerically. However MuSpinSim in this case uses a different algorithm to perform the integral analytically, saving some unnecessary steps. The full derivation of the formula is detailed in this arXiv paper . The essence of it is that, if we have an operator \\(S\\) with matrix elements \\(s_{ij}\\) whose integral value we want to compute: $$ \\langle P \\rangle = \\int_0^\\infty \\langle S \\rangle(t) e^{-\\frac{t}{\\tau}} dt $$ where the integral is weighed with the decay process of the muon with lifetime \\(\\tau\\) , then we can define a new operator \\(P\\) with matrix elements: \\[ p_{ij} = \\frac{s_{ij}}{\\frac{1}{\\tau}-\\frac{i}{\\hbar}\\left(\\lambda_i-\\lambda_j\\right)} \\] and evaluating its expectation value on the initial state of the system will in a single pass return the value of the desired integral. For developers: integral expectation values are handled by the .integrate_decaying() method of the Hamiltonian class. Open systems The Lindblad Master Equation Systems described by the Liouville-von Neumann equation are closed; they conserve energy and evolve in a perfectly reversible way. This is sometimes not a good approximation, because in real life, the chunk of the sample that we're describing is of course only a small part of a much bigger system, fully coupled to it and interacting in a lot of ways. Since including an environment of hundreds or thousands of spins is not practical, a more common approach is to use a master equation that allows to describe irreversible evolution through some kind of energy exchange with environmental degrees of freedom. In MuSpinSim, the only such master equation that is supported is the simplest one, the Lindblad equation. It is an extension of the Liouville-von Neumann equation including dissipative terms: \\[ \\frac{\\partial \\rho}{\\partial t} = -\\frac{i}{\\hbar}[\\mathcal{H}, \\rho] + \\sum_{i=1}^{N^2-1}\\alpha_i\\left(L_i \\rho L_i^\\dagger - \\frac{1}{2}\\left\\{L_i^\\dagger L_i, \\rho\\right\\} \\right) \\] Here the \\(\\alpha_i\\) are coefficients that express the strength of the coupling with a certain degree of freedom, and the \\(L_i\\) are the so-called Lindblad or jump operators of the system, each connected to one coefficient. The curly braces denote the anticommutator of two matrices: \\(\\{A, B\\} = AB+BA\\) . This equation unfortunately does not have a neat solution in exponential form as the one seen above in the matrix formalism. It is however possible to find something very close to it by making a few small changes in the representation, namely, expressing the density matrix in what is called the Fock-Liouville space . An excellent and detailed explanation of this technique is given in this useful introductory paper by Daniel Manzano . The essence of it is that we \"straighten up\" the density matrix, writing all its elements in a single column vector. For example, a \\(4\\times 4\\) matrix can turn into a \\(16\\) elements column vector. It is then possible to write a matrix called the Lindbladian (that in the example will be \\(16 \\times 16\\) ) that operates on it exactly like a Hamiltonian does on a single wavefunction: \\[ \\frac{\\partial}{\\partial t} \\mid \\rho \\rangle\\rangle = \\mathcal{L} \\mid \\rho \\rangle\\rangle \\] and following from that, it is possible to integrate the equations as trivially as seen for the others by diagonalising the Lindbladian. Care must be taken though because unlike for the Hamiltonian, there is no guarantee that the Lindbladian is Hermitian, or for that matter, diagonalizable at all! This can potentially cause issues - however in my experience well-defined systems will be solvable without problems. In MuSpinSim, the only way dissipation can be included in a calculation is by putting an individual spin in contact with a thermal reserve. This is done by defining two jump operators for that spin, \\(S_+^i\\) and \\(S_-^i\\) , and the corresponding dissipation coefficients such that \\[ \\frac{\\alpha_+^i}{\\alpha_-^i} = \\exp\\left(-\\frac{\\hbar\\gamma |B|}{k_BT}\\right) \\] where \\(T\\) is the temperature of the system, and \\(\\hbar\\gamma|B|\\) is an approximation using only the Zeeman interaction of the energy gap between successive states of the spin. For \\(T < \\infty\\) , this is subject to the same limits as the choice of using only the Zeeman interaction to define the initial thermal state density matrix. In fact, the effect of these terms is to tend to drive the individual spin's state towards exactly that thermal state, adding or removing energy as needed and erasing coherences. For developers: the Lindbladian class is defined in muspinsim/lindbladian.py . It has .evolve() and .integrate_decaying() methods analogous to those of the Hamiltonian class. A simple example Let's look at a basic example of a problem that can be solved analytically with the Lindblad master equation to see how it works. Let's consider a single muon immersed in a magnetic field \\(B\\) such that it has Larmor frequency \\(\\omega_L = \\gamma_\\mu B\\) . It is prepared in a state polarised along \\(x\\) , so the initial density matrix is \\[ \\rho_0 = \\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix} \\] and is coupled to an environment with infinite temperature (so \\(\\alpha_+ = \\alpha_- = \\alpha\\) ). The Hamiltonian for this system will then be: \\[ \\mathcal{H} = \\hbar \\omega_L S_z \\] and the jump operators are \\[ S_+ = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix} \\qquad S_- = \\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\end{bmatrix}. \\] Let's write the Lindblad master equation in full: \\[ \\begin{align*} \\frac{\\partial \\rho}{\\partial t} = &i\\omega_L(\\rho S_z-S_z\\rho) + \\\\ & \\alpha\\left(S_+ \\rho S_- + S_- \\rho S_+ - \\frac{1}{2}S_+S_-\\rho - \\frac{1}{2} S_-S_+\\rho - \\frac{1}{2} \\rho S_+S_- - \\frac{1}{2} \\rho S_-S_+ \\right) \\end{align*} \\] where we made use of the fact that \\(S_+^\\dagger = S_-\\) and vice versa. If we write \\(\\rho\\) in terms of its components and expand the products, keeping in mind that it has to be Hermitian, we get: \\[ \\frac{\\partial}{\\partial t}\\begin{bmatrix} \\rho_{11} & \\rho_{12} \\\\ \\rho_{12}^* & \\rho_{22} \\end{bmatrix} = i \\omega_L \\begin{bmatrix} 0 & -r_{12} \\\\ r_{12}^* & 0 \\end{bmatrix} +\\alpha \\left( \\begin{bmatrix} \\rho_{22} & 0 \\\\ 0 & \\rho_{11} \\end{bmatrix} - \\begin{bmatrix} \\rho_{11} & \\rho_{12} \\\\ \\rho_{12}^* & \\rho_{22} \\end{bmatrix} \\right) \\] We can then expand this in three differential equations (we leave out the fourth one as it's just the complex conjugate of one of the others): \\[ \\begin{align*} \\frac{\\partial \\rho_{11}}{\\partial t} = & \\alpha(\\rho_{22}-\\rho_{11}) \\\\ \\frac{\\partial \\rho_{22}}{\\partial t} = & \\alpha(\\rho_{11}-\\rho_{22}) \\\\ \\frac{\\partial \\rho_{12}}{\\partial t} = & -i\\omega_L \\rho_{12} -\\alpha\\rho_{12} \\end{align*} \\] which combined with the initial conditions from the starting density matrix lead to the solutions: \\[ \\begin{align*} \\rho_{11}(t) = & \\rho_{22}(t) = \\frac{1}{2} \\\\ \\rho_{12}(t) = & \\frac{1}{2}e^{-i\\omega_Lt -\\alpha t} \\end{align*} \\] In other words, the evolution has an oscillating phase on the off-diagonal elements plus an exponential decay which brings them down to zero, as the interactions with the environment cause decoherence. In the next section we will look specifically at the exact shape of the terms of the Hamiltonian (and when necessary, Lindbladian) used in MuSpinSim.","title":"Theory of spin dynamics - II"},{"location":"theory_2/#theory-of-spin-dynamics-ii","text":"","title":"Theory of spin dynamics - II"},{"location":"theory_2/#preparing-the-initial-state","text":"When performing a simulation of a muon experiment, the first step is to prepare the system in an appropriate quantum state to evolve under the Hamiltonian. MuSpinSim uses the following rules to prepare this state: the muon is prepared in a state polarised along the direction of the beam (conventionally, the x axis in the laboratory frame of reference); every other spin is prepared in a thermal density matrix state. A thermal density matrix state simply means a state in which every energy level is populated with a probability following the Boltzmann distribution, and fully decohered otherwise. In other words: \\[ \\rho_{th}(T) = \\frac{e^{-\\frac{\\mathcal{H}}{k_BT}}}{\\mathrm{Tr}\\left(e^{-\\frac{\\mathcal{H}}{k_BT}}\\right)} \\] where the trace below is the partition function of the system. One can see how finding this matrix would in principle require diagonalising the Hamiltonian of the whole system the muon is being inserted in. In practice, in MuSpinSim we use one of two approximations: by default, the \\(T=\\infty\\) approximation is used, in which all states are equally populated. The advantage of this approximation is that it's completely invariant to any change of basis - it doesn't make a difference what exactly the eigenstates of the Hamiltonian are. The real temperature of the sample, of course, is not infinite, but as long as \\(k_BT \\gg \\mathcal{H}\\) , that's a fair enough approximation; if requested by the user, finite temperature can be used, but the Hamiltonian is simplified to the Zeeman Hamiltonian, \\(\\mathcal{H} \\approx \\hbar \\sum_i\\gamma_i \\mathbf{B}\\mathbf{S}^{(i)}\\) . This approximation keeps all spins independent from each other, ignoring their possible couplings, and is very effective in the case in which a strong magnetic field is applied and the Zeeman term is prevalent in the Hamiltonian. It should not be used for zero field experiment simulations. For developers: the initial density matrix is calculated in the property .rho0() of the class ExperimentRunner , found in muspinsim/experiment.py .","title":"Preparing the initial state"},{"location":"theory_2/#time-evolution","text":"","title":"Time evolution"},{"location":"theory_2/#closed-system","text":"Time evolution for the density matrix of a closed quantum system is controlled by the Liouville-von Neumann equation that we've already seen: \\[ \\frac{\\partial \\rho}{\\partial t} = -\\frac{i}{\\hbar}[\\mathcal{H}, \\rho] \\] If we write the matrix quantities with indices (repeated indices imply summation) we can write this as a system of coupled differential equations for each individual coefficient: \\[ \\frac{\\partial \\rho_{ij}}{\\partial t} = -\\frac{i}{\\hbar}\\left(\\mathcal{H}_{ik}\\rho_{kj}-\\rho_{ik}\\mathcal{H}_{kj}\\right) \\] This gets significantly simpler when we express both the matrices in a basis in which the Hamiltonian is diagonal, and thus \\(\\mathcal{H}_{ij} = \\lambda_i\\delta_{ij}\\) : \\[ \\frac{\\partial \\rho_{ij}}{\\partial t} = -\\frac{i}{\\hbar}\\rho_{ij}\\left(\\lambda_i-\\lambda_j\\right) \\qquad \\implies \\qquad \\rho_{ij}(t) = e^{-\\frac{i}{\\hbar}\\left(\\lambda_i-\\lambda_j\\right) t}\\rho_{ij}(0) \\] This way we can see that the equations are completely decoupled. Coefficients on the diagonal of the density matrix don't change, while off-diagonal coefficients gain a phase factor at a constant rate that is dependent on the differences between the Hamiltonian eigenvalues. This method gives us the exact evolution of the system and perfectly preserves unitarity. The downside of it is that it requires a full diagonalization of the Hamiltonian. However, many spin systems that we are interested in are relatively small, and one single diagonalisation for each of them isn't a big deal. For a cheaper, more approximate method see Celio's Method . For developers: time evolution of a system is handled by the .evolve() method of the Hamiltonian class.","title":"Closed system"},{"location":"theory_2/#a-faster-method","text":"When simulating systems where \\(\\frac{B}{T} \\rightarrow 0\\) , i.e. when we have zero external magnetic field or the temperature \\(T \\rightarrow \\infty\\) , MuSpinSim will automatically employ a faster method of time evolution. To explain this method we first note that the density matrix at \\(t=0\\) for the muon polarised along a direction \\({\\hat n}\\) can be written as \\[ \\rho_\\mu (t=0) = \\frac{1}{2}(\\mathbb{1} + \\sigma_\\mu^{\\hat n}), \\] and hence the density matrix of the full system is, (defining \\(d =\\prod_{i \\neq 0} 2I_i + 1\\) as the dimension of the Hilbert space without the muon) \\[ \\rho(t=0) = \\frac{1}{2}(\\mathbb{1}+\\sigma_\\mu^{\\hat n}) \\otimes \\frac{1}{d}\\mathbb{1}_d. \\] Here we want to calculate the time dependence of the muon polarisation along \\({\\hat n}\\) , which is given by (notational abuse means \\(\\sigma_\\mu^{\\hat n}(t) = e^{-\\frac{i}{\\hbar}Ht}(\\sigma_\\mu^{\\hat n} \\otimes \\mathbb{1}_d) e^{\\frac{i}{\\hbar}Ht}\\) ) \\[ P^{\\hat n}_\\mu(t) = \\mathrm{Tr}[\\rho(t)\\sigma_\\mu^{\\hat n}(0)] = \\mathrm{Tr}[\\rho(t=0)\\sigma_\\mu^{\\hat n}(t)]. \\] We have also switched which operator we are time-evolving on the RHS here. Now, substituting \\(\\rho(t=0)\\) , we get \\[ P^{\\hat n}_\\mu(t) = \\mathrm{Tr}[\\rho(t=0)\\sigma_\\mu^{\\hat n}(t)]= \\mathrm{Tr}\\Bigg[\\Big(\\frac{1}{2}(\\mathbb{1}+\\sigma_\\mu^{\\hat n}) \\otimes \\frac{1}{d}\\mathbb{1}_{d} \\Big)\\sigma_\\mu^{\\hat n}(t)\\Bigg] \\] which can be simplified to \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\mathrm{Tr}\\Bigg[\\Big((\\mathbb{1}+\\sigma_\\mu^{\\hat n}) \\otimes \\mathbb{1}_{d} \\Big)\\sigma_\\mu^{\\hat n}(t)\\Bigg]. \\] Now, if we factor out the first term in the trace, we get \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\mathrm{Tr}[(\\mathbb{1} \\otimes \\mathbb{1}_{d}) \\sigma_\\mu^{\\hat n}(t)] +\\frac{1}{2d}\\mathrm{Tr}\\Bigg[(\\sigma_\\mu^{\\hat n} \\otimes \\mathbb{1}_{d}) \\sigma_\\mu^{\\hat n}(t)\\Bigg]. \\] Note that ass the trace of a Pauli spin matrix is always zero, only the second term is non-zero. Hence the muon polarisation can be written as (after re-defining \\(\\sigma_\\mu^{\\hat n}\\) to include the kronecker product with the identity matrix of the other spins) \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\mathrm{Tr}\\Bigg[\\sigma_\\mu^{\\hat n}(0) \\sigma_\\mu^{\\hat n}(t)\\Bigg]. \\] Now replacing the trace with \\(\\sum_\\alpha \\langle \\alpha| ... | \\alpha \\rangle\\) , where \\(| \\alpha \\rangle\\) is a complete set of orthonormal eigenstates we obtain \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_\\alpha \\langle \\alpha | \\Bigg[\\sigma_\\mu^{\\hat n}(0) \\sigma_\\mu^{\\hat n}(t)\\Bigg] | \\alpha \\rangle. \\] Explicitly writing out the time dependance, we get \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha, \\beta, \\gamma} \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle e^{iE_\\beta t} \\langle \\beta | \\sigma_\\mu^{\\hat n}(0) |\\gamma \\rangle e^{-iE_\\gamma t} \\langle \\gamma | \\alpha \\rangle, \\] and as \\(\\langle \\gamma | \\alpha \\rangle = \\delta_{\\gamma, \\alpha}\\) , this simplifies to \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha, \\beta} \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle e^{iE_\\beta t} \\langle \\beta | \\sigma_\\mu^{\\hat n}(0) |\\alpha \\rangle e^{-iE_\\alpha t}, \\] so that \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha, \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t}. \\] Then, we can separate these terms into \\[ \\begin{aligned} P^{\\hat n}_\\mu(t) & = \\frac{1}{2d}\\sum_{\\alpha = \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t} \\\\ & + \\frac{1}{2d}\\sum_{\\alpha < \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t} + \\frac{1}{2d}\\sum_{\\alpha > \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t}. \\end{aligned} \\] Now by swapping \\(\\alpha\\) and \\(\\beta\\) in the last term, we see that it is the same as the second term apart from a sign in the exponential, so they may combined to give \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha = \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 e^{i(E_\\beta-E_\\alpha) t} + \\frac{1}{2d}\\sum_{\\alpha < \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 [e^{i(E_\\beta-E_\\alpha) t} + e^{-i(E_\\beta-E_\\alpha) t}]. \\] Finally, by expressing the exponentials in terms of \\(\\sin\\) and \\(\\cos\\) , we may simplify the expression to \\[ P^{\\hat n}_\\mu(t) = \\frac{1}{2d}\\sum_{\\alpha = \\beta}\\Big|\\langle\\alpha|\\sigma_{\\mu}^{\\hat{n}}|\\beta\\rangle\\Big|^2 + \\frac{1}{d}\\sum_{\\alpha < \\beta} \\Big| \\langle \\alpha | \\sigma_\\mu^{\\hat n}(0) |\\beta \\rangle \\Big|^2 \\cos [(E_\\beta-E_\\alpha) t]. \\] When installed with OpenMP, MuSpinSim will parallelise this method over the time values, so when computing for 100 times, it will run on up to 100 threads. For developers: this time evolution of a system is handled by the .fast_evolve() method of the Hamiltonian class.","title":"A faster method"},{"location":"theory_2/#celios-method","text":"MuSpinSim can also make use of an approximation to speedup calculations and reduce memory usage in certain cases using Celio's method . To do this we first split up the Hamiltonian into contributions from each interaction. \\[ H = \\sum_{i}^{N} H_i \\] Then referring back to the earlier result \\[ \\rho(t) = e^{-\\frac{i}{\\hbar}Ht}\\rho(0)e^{\\frac{i}{\\hbar}Ht}. \\] We expand using the Suzuki\u2013Trotter formula \\[ e^{H_1 + H_2} = \\lim_{k\\rightarrow\\infty}{\\left[e^{\\frac{H_1}{k}}e^{\\frac{H_2}{k}}\\right]^k} \\] To obtain \\[ e^{-\\frac{i}{\\hbar}Ht} = \\lim_{k\\rightarrow\\infty}{\\left[\\prod_{i}^{N}e^{-\\frac{i}{k\\hbar}H_it}\\right]^k} \\] This allows us to compute the evolution operator while avoiding the diagonalisation of the Hamiltonian. In reality this formula is a simplification as each \\(H_i\\) acts in a smaller subspace of dimension determined by the spins involved in the interaction it describes. As a result, in computing this product in terms of matrices, we must also do the kronecker product with identity matrices that match the dimensions of the other particles in the system. We also use swap gates to ensure the order of these kronecker products is preserved. As an example, taking system of a muon and two electrons (labelled 1, 2 and 3 respectively) with a single dipolar interaction defined between the muon and second electron we compute \\[ e^{-\\frac{i}{\\hbar}Ht} = \\lim_{k\\rightarrow\\infty}{\\left[\\text{SWAP}_{32} \\left( \\mathbb{1}_2 \\otimes e^{-\\frac{i}{k\\hbar}H_{13}t}\\right)\\right]^k} \\] Where \\(H_{12}\\) is the contribution from the dipolar interaction and \\(\\mathbb{1}_2\\) is the identity matrix of size \\(2I + 1 = 2\\) (For the first electron). \\(\\text{SWAP}_{32}\\) is a swap gate that has the effect of reversing the kronecker products into the correct order and is required since \\(H_{13}\\) is formed in a subspace with only particles 1 and 3 whereas it should be computed for the system with particles 1, 2 and 3 in that order. Due to the extra matrix products this method is most suitable when the evolution operator's matrix is sparse for which it will be faster and will use significantly less memory. This will generally be the case for larger spins with a few simple interactions. MuSpinSim will log a warning in its output if the sparsity doesn't appear suitable for this variant Celio's method.","title":"Celio's Method"},{"location":"theory_2/#further-speedup","text":"For a further speedup we can continue to follow Celio's method, approximating the initial state of the system provided that \\(T\\rightarrow \\infty\\) and use this to provide a large increase in performance. This method is also less susceptible to matrices becoming dense allowing the evolution of more complex systems but with a lower accuracy. Here instead of evolving the density matrix, we instead evolve \\(\\sigma_{\\mu}=2I_{\\mu}\\) which are the Pauli matrices in the direction of the muon. \\[ \\sigma_{\\mu}(t) = e^{-\\frac{i}{\\hbar}Ht}\\sigma_{\\mu}e^{\\frac{i}{\\hbar}Ht} \\] Then by choosing a representation where \\(\\sigma_{\\mu}\\) is diagonal we can write the muon polarisation as \\[ P(t) = \\sum_{n=1}^{d}{w_n\\bra{\\psi_n(t)}\\sigma_{\\mu}\\ket{\\psi_n(t)}} \\] where d is the total dimension of the system and \\[ \\ket{\\psi_n(t)} = e^{\\frac{-iHt}{\\hbar}}\\ket{\\psi_n(0)} \\] gives the time evolution of the initial approximated states. The coefficients \\(w_n\\) here describe the probability of finding the spin system in the state \\(\\ket{\\psi_n(0)}\\) at \\(t = 0\\) . In standard experimental conditions these are determined as \\[ w_n = \\frac{2}{d}\\text{ if }\\sigma_{\\mu}\\ket{\\psi_n(0)} = + \\ket{\\psi_n(0)} \\] \\[ w_n = 0\\text{ if }\\sigma_{\\mu}\\ket{\\psi_n(0)} = - \\ket{\\psi_n(0)} \\] Thus we can diagonalise the density matrix for the muon given by \\[ \\rho = \\mathbb{1}_2 + \\sigma_{\\mu} \\] and choose the eigenvector with a positive eigenvalue to obtain the initial state \\(\\ket{\\psi(0)}\\) Now we define the total initial state of the system as \\[ \\ket{\\phi(0)} = \\sum_{m=1}^{d/2}\\left(\\frac{2}{d}\\right)^{1/2}e^{i\\lambda_m}\\ket{\\psi_m(0)} \\] where \\(\\lambda_m\\) is chosen randomly in the range \\([0, 2\\pi]\\) . Then the state at a later time t is given by \\[ \\ket{\\phi(t)} = \\sum_{m=1}^{d/2}\\left(\\frac{2}{d}\\right)^{1/2}e^{i\\lambda_m}\\ket{\\psi_m(t)} \\] and the matrix elements are given by \\[ \\bra{\\phi(t)}\\sigma_{\\mu}\\ket{\\phi(t)} = \\sum_{m=1}^{d/2}\\frac{2}{d}\\bra{\\psi_m(t)}\\sigma_{\\mu}\\ket{\\psi_m(t)} + \\sum_{m,n=1, m\\neq n}^{d/2}\\frac{2}{d}e^{i(\\lambda_m - \\lambda_n)}\\bra{\\psi_n(t)}\\sigma_{\\mu}\\ket{\\psi_m(t)} \\] This second term vanishes for very large \\(d\\) allowing us to avoid very large matrix products which speeds up the method drastically. When installed with OpenMP, MuSpinSim will parallelise this method over the values of \\(m\\) . For developers: time evolution of a system using Celio's method is handled by the .evolve() and .fast_evolve() methods of the CelioHamiltonian class.","title":"Further speedup"},{"location":"theory_2/#integral-of-asymmetry","text":"In muon experiments we're usually interested in measuring the asymmetry of positron hits between the forward and back detectors in the experimental setup - namely, the polarisation of the muon along a certain axis, as it evolves in time. However, in some cases (like ALC experiments) what we actually care about is the integral of this asymmetry throughout a certain time interval. This could be trivially computed simply by computing the time evolution and then integrating numerically. However MuSpinSim in this case uses a different algorithm to perform the integral analytically, saving some unnecessary steps. The full derivation of the formula is detailed in this arXiv paper . The essence of it is that, if we have an operator \\(S\\) with matrix elements \\(s_{ij}\\) whose integral value we want to compute: $$ \\langle P \\rangle = \\int_0^\\infty \\langle S \\rangle(t) e^{-\\frac{t}{\\tau}} dt $$ where the integral is weighed with the decay process of the muon with lifetime \\(\\tau\\) , then we can define a new operator \\(P\\) with matrix elements: \\[ p_{ij} = \\frac{s_{ij}}{\\frac{1}{\\tau}-\\frac{i}{\\hbar}\\left(\\lambda_i-\\lambda_j\\right)} \\] and evaluating its expectation value on the initial state of the system will in a single pass return the value of the desired integral. For developers: integral expectation values are handled by the .integrate_decaying() method of the Hamiltonian class.","title":"Integral of asymmetry"},{"location":"theory_2/#open-systems","text":"","title":"Open systems"},{"location":"theory_2/#the-lindblad-master-equation","text":"Systems described by the Liouville-von Neumann equation are closed; they conserve energy and evolve in a perfectly reversible way. This is sometimes not a good approximation, because in real life, the chunk of the sample that we're describing is of course only a small part of a much bigger system, fully coupled to it and interacting in a lot of ways. Since including an environment of hundreds or thousands of spins is not practical, a more common approach is to use a master equation that allows to describe irreversible evolution through some kind of energy exchange with environmental degrees of freedom. In MuSpinSim, the only such master equation that is supported is the simplest one, the Lindblad equation. It is an extension of the Liouville-von Neumann equation including dissipative terms: \\[ \\frac{\\partial \\rho}{\\partial t} = -\\frac{i}{\\hbar}[\\mathcal{H}, \\rho] + \\sum_{i=1}^{N^2-1}\\alpha_i\\left(L_i \\rho L_i^\\dagger - \\frac{1}{2}\\left\\{L_i^\\dagger L_i, \\rho\\right\\} \\right) \\] Here the \\(\\alpha_i\\) are coefficients that express the strength of the coupling with a certain degree of freedom, and the \\(L_i\\) are the so-called Lindblad or jump operators of the system, each connected to one coefficient. The curly braces denote the anticommutator of two matrices: \\(\\{A, B\\} = AB+BA\\) . This equation unfortunately does not have a neat solution in exponential form as the one seen above in the matrix formalism. It is however possible to find something very close to it by making a few small changes in the representation, namely, expressing the density matrix in what is called the Fock-Liouville space . An excellent and detailed explanation of this technique is given in this useful introductory paper by Daniel Manzano . The essence of it is that we \"straighten up\" the density matrix, writing all its elements in a single column vector. For example, a \\(4\\times 4\\) matrix can turn into a \\(16\\) elements column vector. It is then possible to write a matrix called the Lindbladian (that in the example will be \\(16 \\times 16\\) ) that operates on it exactly like a Hamiltonian does on a single wavefunction: \\[ \\frac{\\partial}{\\partial t} \\mid \\rho \\rangle\\rangle = \\mathcal{L} \\mid \\rho \\rangle\\rangle \\] and following from that, it is possible to integrate the equations as trivially as seen for the others by diagonalising the Lindbladian. Care must be taken though because unlike for the Hamiltonian, there is no guarantee that the Lindbladian is Hermitian, or for that matter, diagonalizable at all! This can potentially cause issues - however in my experience well-defined systems will be solvable without problems. In MuSpinSim, the only way dissipation can be included in a calculation is by putting an individual spin in contact with a thermal reserve. This is done by defining two jump operators for that spin, \\(S_+^i\\) and \\(S_-^i\\) , and the corresponding dissipation coefficients such that \\[ \\frac{\\alpha_+^i}{\\alpha_-^i} = \\exp\\left(-\\frac{\\hbar\\gamma |B|}{k_BT}\\right) \\] where \\(T\\) is the temperature of the system, and \\(\\hbar\\gamma|B|\\) is an approximation using only the Zeeman interaction of the energy gap between successive states of the spin. For \\(T < \\infty\\) , this is subject to the same limits as the choice of using only the Zeeman interaction to define the initial thermal state density matrix. In fact, the effect of these terms is to tend to drive the individual spin's state towards exactly that thermal state, adding or removing energy as needed and erasing coherences. For developers: the Lindbladian class is defined in muspinsim/lindbladian.py . It has .evolve() and .integrate_decaying() methods analogous to those of the Hamiltonian class.","title":"The Lindblad Master Equation"},{"location":"theory_2/#a-simple-example","text":"Let's look at a basic example of a problem that can be solved analytically with the Lindblad master equation to see how it works. Let's consider a single muon immersed in a magnetic field \\(B\\) such that it has Larmor frequency \\(\\omega_L = \\gamma_\\mu B\\) . It is prepared in a state polarised along \\(x\\) , so the initial density matrix is \\[ \\rho_0 = \\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2} \\end{bmatrix} \\] and is coupled to an environment with infinite temperature (so \\(\\alpha_+ = \\alpha_- = \\alpha\\) ). The Hamiltonian for this system will then be: \\[ \\mathcal{H} = \\hbar \\omega_L S_z \\] and the jump operators are \\[ S_+ = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix} \\qquad S_- = \\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\end{bmatrix}. \\] Let's write the Lindblad master equation in full: \\[ \\begin{align*} \\frac{\\partial \\rho}{\\partial t} = &i\\omega_L(\\rho S_z-S_z\\rho) + \\\\ & \\alpha\\left(S_+ \\rho S_- + S_- \\rho S_+ - \\frac{1}{2}S_+S_-\\rho - \\frac{1}{2} S_-S_+\\rho - \\frac{1}{2} \\rho S_+S_- - \\frac{1}{2} \\rho S_-S_+ \\right) \\end{align*} \\] where we made use of the fact that \\(S_+^\\dagger = S_-\\) and vice versa. If we write \\(\\rho\\) in terms of its components and expand the products, keeping in mind that it has to be Hermitian, we get: \\[ \\frac{\\partial}{\\partial t}\\begin{bmatrix} \\rho_{11} & \\rho_{12} \\\\ \\rho_{12}^* & \\rho_{22} \\end{bmatrix} = i \\omega_L \\begin{bmatrix} 0 & -r_{12} \\\\ r_{12}^* & 0 \\end{bmatrix} +\\alpha \\left( \\begin{bmatrix} \\rho_{22} & 0 \\\\ 0 & \\rho_{11} \\end{bmatrix} - \\begin{bmatrix} \\rho_{11} & \\rho_{12} \\\\ \\rho_{12}^* & \\rho_{22} \\end{bmatrix} \\right) \\] We can then expand this in three differential equations (we leave out the fourth one as it's just the complex conjugate of one of the others): \\[ \\begin{align*} \\frac{\\partial \\rho_{11}}{\\partial t} = & \\alpha(\\rho_{22}-\\rho_{11}) \\\\ \\frac{\\partial \\rho_{22}}{\\partial t} = & \\alpha(\\rho_{11}-\\rho_{22}) \\\\ \\frac{\\partial \\rho_{12}}{\\partial t} = & -i\\omega_L \\rho_{12} -\\alpha\\rho_{12} \\end{align*} \\] which combined with the initial conditions from the starting density matrix lead to the solutions: \\[ \\begin{align*} \\rho_{11}(t) = & \\rho_{22}(t) = \\frac{1}{2} \\\\ \\rho_{12}(t) = & \\frac{1}{2}e^{-i\\omega_Lt -\\alpha t} \\end{align*} \\] In other words, the evolution has an oscillating phase on the off-diagonal elements plus an exponential decay which brings them down to zero, as the interactions with the environment cause decoherence. In the next section we will look specifically at the exact shape of the terms of the Hamiltonian (and when necessary, Lindbladian) used in MuSpinSim.","title":"A simple example"},{"location":"tools/","text":"Tools muspinsim-gen muspinsim-gen is a command line tool made to help construct an input file given a cell structure file as input. At the moment it can take an input structure (defined in a file supported by ase e.g. a .cell or .cif), find a requested number of nearest neighbour atoms to the muon, and then output the muspinsim config defining these atoms and the dipolar interactions with the muon. It can also (optionally) take a file containing output defining EFG tensors from GIPAW in order to include quadrupole interactions. The available command line options can be found by invoking muspinsim-gen --help . Example Taking a cell file named V3Si.cell you may use muspinsim-gen ./V3Si.cell 6 --dipolar --out V3Si.in Note The muon is assumed to be defined in the structure as H , this can be modified by the command line option --muon_symbol MUON_SYMBOL . This takes the cell file, then iteratively expands the structure outwards to find the closest 6 atoms to the muon. Then it computes vectors between each of the found atoms and the muon before outputting the muspinsim config into the file V3Si.in which looks like spins mu V V V V Si Si dipolar 1 2 5.8867821595143255e-06 -1.2410298376667999 1.2417097773151198 dipolar 1 3 -1.2410421175142399 1.7637655919999997e-05 -1.2417029559655202 dipolar 1 4 1.2410539563139198 1.7614965359999998e-05 -1.2417021305964 dipolar 1 5 5.8811095198230134e-06 1.2410652462856788 1.2417072770990398 dipolar 1 6 5.84849183971059e-06 -2.377947784716 -1.18857807822936 dipolar 1 7 -2.37795896407128 1.786314336e-05 1.18858129319808 Warning By default, MuSpinSim assumes that the atoms present have a non-zero spin (in this case, 29Si with a spin of 1/2). To avoid interactions between the muon and Si (effectively treating it as the more abundant, spin-zero 28Si) we can use --ignore_symbol Si . Additional ignored symbols can be added by repeating this option. To add quadrupole interactions you may use --quadrupolar GIPAW_FILEPATH . This file should contain the output of GIPAW from calculating the EFG tensors on the same structure. These will then be matched to the found atoms and will be output into the file.","title":"Tools"},{"location":"tools/#tools","text":"","title":"Tools"},{"location":"tools/#muspinsim-gen","text":"muspinsim-gen is a command line tool made to help construct an input file given a cell structure file as input. At the moment it can take an input structure (defined in a file supported by ase e.g. a .cell or .cif), find a requested number of nearest neighbour atoms to the muon, and then output the muspinsim config defining these atoms and the dipolar interactions with the muon. It can also (optionally) take a file containing output defining EFG tensors from GIPAW in order to include quadrupole interactions. The available command line options can be found by invoking muspinsim-gen --help .","title":"muspinsim-gen"},{"location":"tools/#example","text":"Taking a cell file named V3Si.cell you may use muspinsim-gen ./V3Si.cell 6 --dipolar --out V3Si.in Note The muon is assumed to be defined in the structure as H , this can be modified by the command line option --muon_symbol MUON_SYMBOL . This takes the cell file, then iteratively expands the structure outwards to find the closest 6 atoms to the muon. Then it computes vectors between each of the found atoms and the muon before outputting the muspinsim config into the file V3Si.in which looks like spins mu V V V V Si Si dipolar 1 2 5.8867821595143255e-06 -1.2410298376667999 1.2417097773151198 dipolar 1 3 -1.2410421175142399 1.7637655919999997e-05 -1.2417029559655202 dipolar 1 4 1.2410539563139198 1.7614965359999998e-05 -1.2417021305964 dipolar 1 5 5.8811095198230134e-06 1.2410652462856788 1.2417072770990398 dipolar 1 6 5.84849183971059e-06 -2.377947784716 -1.18857807822936 dipolar 1 7 -2.37795896407128 1.786314336e-05 1.18858129319808 Warning By default, MuSpinSim assumes that the atoms present have a non-zero spin (in this case, 29Si with a spin of 1/2). To avoid interactions between the muon and Si (effectively treating it as the more abundant, spin-zero 28Si) we can use --ignore_symbol Si . Additional ignored symbols can be added by repeating this option. To add quadrupole interactions you may use --quadrupolar GIPAW_FILEPATH . This file should contain the output of GIPAW from calculating the EFG tensors on the same structure. These will then be matched to the found atoms and will be output into the file.","title":"Example"},{"location":"tutorial/","text":"Tutorial Usage From the command line Once installed, MuSpinSim will be available for command line use as muspinsim . To run it you may use the following syntax muspinsim input_file.in where the input file contains the parameters specifying the system and experiment details. For especially expensive calculations MuSpinSim can also be used in parallel with MPI. In that case, the command to run it is mpirun -n <number of cores> muspinsim.mpi input_file.in where <number of cores> is replaced by the number of desired cores on the given system. Example Create a file named zeeman.in with the following text name zeeman spins mu time range(0, 0.1, 100) zeeman 1 0 0 20.0/muon_gyr This represents the input file for a simple system with a single muon and static electric field aligned in the z axis. This gives the general structure of input files, for more information see Input . When you give this file as input to MuSpinSim it will compute and output the time evolution of the muon's polarisation (asymmetry) in the time range from 0 to 0.1 microseconds in 100 steps. To do this run the command muspinsim zeeman.in This will generate an output of the time and asymmetry values in zeeman.dat . The name of this file is the name given in the input file above. This output file will look something like # MUSPINSIM v.1.2.0 # Output file written on Mon Nov 7 09:28:54 2022 # Parameters used: # 0.000000000000000000e+00 5.000000000000000000e-01 1.010101010101010100e-03 4.959774064153976703e-01 2.020202020202020200e-03 4.839743506981781240e-01 ... The first value on each row is the time value, and the second is the computed asymmetry. You should also see the presence of a log file named zeeman.log which can give additional information on what MuSpinSim has done. For further information on this example as well as others see Examples . As a library MuSpinSim can also be used as a Python library within larger programs. The simplest way to do so is to use an input file to configure a problem, read it in with the MuSpinInput class, then use it to create a MuonExperimentalSetup that runs the actual experiment. The minimal script is: from muspinsim import MuSpinInput, ExperimentRunner params = MuSpinInput(open('input_file.in')) experiment = ExperimentRunner(params) results = experiment.run() In order to instead run a fitting calculation, the minimal script is from muspinsim import MuSpinInput, FittingRunner params = MuSpinInput(open('input_file.in')) optimizer = FittingRunner(params) solution = optimizer.run() For parallel use, it's recommended to stick to using the provided muspinsim.mpi script.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"","title":"Tutorial"},{"location":"tutorial/#usage","text":"","title":"Usage"},{"location":"tutorial/#from-the-command-line","text":"Once installed, MuSpinSim will be available for command line use as muspinsim . To run it you may use the following syntax muspinsim input_file.in where the input file contains the parameters specifying the system and experiment details. For especially expensive calculations MuSpinSim can also be used in parallel with MPI. In that case, the command to run it is mpirun -n <number of cores> muspinsim.mpi input_file.in where <number of cores> is replaced by the number of desired cores on the given system.","title":"From the command line"},{"location":"tutorial/#example","text":"Create a file named zeeman.in with the following text name zeeman spins mu time range(0, 0.1, 100) zeeman 1 0 0 20.0/muon_gyr This represents the input file for a simple system with a single muon and static electric field aligned in the z axis. This gives the general structure of input files, for more information see Input . When you give this file as input to MuSpinSim it will compute and output the time evolution of the muon's polarisation (asymmetry) in the time range from 0 to 0.1 microseconds in 100 steps. To do this run the command muspinsim zeeman.in This will generate an output of the time and asymmetry values in zeeman.dat . The name of this file is the name given in the input file above. This output file will look something like # MUSPINSIM v.1.2.0 # Output file written on Mon Nov 7 09:28:54 2022 # Parameters used: # 0.000000000000000000e+00 5.000000000000000000e-01 1.010101010101010100e-03 4.959774064153976703e-01 2.020202020202020200e-03 4.839743506981781240e-01 ... The first value on each row is the time value, and the second is the computed asymmetry. You should also see the presence of a log file named zeeman.log which can give additional information on what MuSpinSim has done. For further information on this example as well as others see Examples .","title":"Example"},{"location":"tutorial/#as-a-library","text":"MuSpinSim can also be used as a Python library within larger programs. The simplest way to do so is to use an input file to configure a problem, read it in with the MuSpinInput class, then use it to create a MuonExperimentalSetup that runs the actual experiment. The minimal script is: from muspinsim import MuSpinInput, ExperimentRunner params = MuSpinInput(open('input_file.in')) experiment = ExperimentRunner(params) results = experiment.run() In order to instead run a fitting calculation, the minimal script is from muspinsim import MuSpinInput, FittingRunner params = MuSpinInput(open('input_file.in')) optimizer = FittingRunner(params) solution = optimizer.run() For parallel use, it's recommended to stick to using the provided muspinsim.mpi script.","title":"As a library"}]}